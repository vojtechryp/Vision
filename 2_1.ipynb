{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1 \n",
    "\n",
    "In this task you will carry out a classification task for a subset of CIFAR-10/100 data using PyTorch. The data and images needed for the task are in the 2 1 folder. Follow the instructions below to complete this task. Complete your code in the provided Notebook file.\n",
    "\n",
    "Submit this notebook file alongside the report and model checkpoint. In this task, we will beperforming transfer learning on the CIFAR-10/100 Dataset. You will be expected to load inexisting pre-trained models, adapt said models for the current task and optimise the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "import sys \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform, loader, data, batch, and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformation of the datasets\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # Resize images to the input size of VGG16\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize images\n",
    "])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_dataset = ImageFolder(root='CIFAR-10/train', transform=data_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_dataset = ImageFolder(root='CIFAR-10/test', transform=data_transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def plt_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.cpu().numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified VGG16 net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModifiedVGG16(\n",
      "  (vgg16): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): ReLU(inplace=True)\n",
      "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (15): ReLU(inplace=True)\n",
      "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (18): ReLU(inplace=True)\n",
      "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (20): ReLU(inplace=True)\n",
      "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (22): ReLU(inplace=True)\n",
      "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (25): ReLU(inplace=True)\n",
      "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (27): ReLU(inplace=True)\n",
      "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (29): ReLU(inplace=True)\n",
      "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ModifiedVGG16(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ModifiedVGG16, self).__init__()\n",
    "        # Load the pre-trained VGG16 model\n",
    "        self.vgg16 = models.vgg16(weights='IMAGENET1K_V1')\n",
    "        \n",
    "        # Modify the last fully connected layer to output 10 classes\n",
    "        self.vgg16.classifier[6] = nn.Linear(4096, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vgg16(x)\n",
    "        return x\n",
    "\n",
    "modified_model_CIFAR_10 = ModifiedVGG16(num_classes=10)\n",
    "print(modified_model_CIFAR_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(modified_model_CIFAR_10.parameters(),lr=0.01,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('./2_1/runs\"')\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(device)\n",
    "\n",
    "# Function to train for one epoch\n",
    "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    mean_loss = torch.zeros(1).to(device)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Wrap data_loader with tqdm for progress bar\n",
    "    data_loader = tqdm(data_loader, file=sys.stdout)\n",
    "\n",
    "    for iter, data in enumerate(data_loader):\n",
    "\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs = data[0].to(device)\n",
    "        labels = data[1].to(device)\n",
    "\n",
    "        net_out = model(inputs)\n",
    "\n",
    "        loss = criterion(net_out, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        mean_loss = (mean_loss * iter + loss.detach()) / (iter + 1)\n",
    "        data_loader.desc = f\"[epoch{epoch}] mean_loss: {round(mean_loss.item(), 5)}\"\n",
    "\n",
    "        if not torch.isfinite(loss):\n",
    "            print(\"ending training\", loss)\n",
    "            sys.exit(1)\n",
    "            \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # torch.save(model.state_dict(), f\"{arg.save_weights}/model-{epoch}.pth\")\n",
    "\n",
    "    return mean_loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classes(model, images, labels):\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(images)\n",
    "        preds_softmax = F.softmax(preds, dim=1)\n",
    "        pred_probs, pred_labels = torch.max(preds_softmax, dim=1)\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in range(min(4, images.shape[0])):  # Show 4 images from batch\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        plt_imshow(images[idx], one_channel=False)\n",
    "        ax.set_title(f\"{classes[pred_labels[idx]]}, {pred_probs[idx]:.5f}\\n(label: {classes[labels[idx]]})\",\n",
    "                     color=(\"green\" if pred_labels[idx] == labels[idx] else \"red\"))\n",
    "    \n",
    "    writer.add_figure('predictions vs. actuals', fig, step)\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch0] mean_loss: 1.86079: 100%|██████████| 16/16 [00:14<00:00,  1.09it/s]\n",
      "Epoch 1/20, Train Loss: 1.86079\n",
      "[epoch1] mean_loss: 1.25327: 100%|██████████| 16/16 [00:13<00:00,  1.22it/s]\n",
      "Epoch 2/20, Train Loss: 1.25327\n",
      "[epoch2] mean_loss: 0.9262: 100%|██████████| 16/16 [00:14<00:00,  1.11it/s] \n",
      "Epoch 3/20, Train Loss: 0.92620\n",
      "[epoch3] mean_loss: 0.5873: 100%|██████████| 16/16 [00:13<00:00,  1.21it/s] \n",
      "Epoch 4/20, Train Loss: 0.58730\n",
      "[epoch4] mean_loss: 0.44618: 100%|██████████| 16/16 [00:13<00:00,  1.19it/s]\n",
      "Epoch 5/20, Train Loss: 0.44618\n",
      "[epoch5] mean_loss: 0.3361: 100%|██████████| 16/16 [00:13<00:00,  1.21it/s] \n",
      "Epoch 6/20, Train Loss: 0.33610\n",
      "[epoch6] mean_loss: 0.20926: 100%|██████████| 16/16 [00:13<00:00,  1.22it/s]\n",
      "Epoch 7/20, Train Loss: 0.20926\n",
      "[epoch7] mean_loss: 0.15599: 100%|██████████| 16/16 [00:15<00:00,  1.06it/s]\n",
      "Epoch 8/20, Train Loss: 0.15599\n",
      "[epoch8] mean_loss: 0.12057: 100%|██████████| 16/16 [00:14<00:00,  1.13it/s]\n",
      "Epoch 9/20, Train Loss: 0.12057\n",
      "[epoch9] mean_loss: 0.0864: 100%|██████████| 16/16 [00:13<00:00,  1.22it/s] \n",
      "Epoch 10/20, Train Loss: 0.08640\n",
      "[epoch10] mean_loss: 0.10205: 100%|██████████| 16/16 [00:13<00:00,  1.15it/s]\n",
      "Epoch 11/20, Train Loss: 0.10205\n",
      "[epoch11] mean_loss: 0.0541: 100%|██████████| 16/16 [00:14<00:00,  1.13it/s] \n",
      "Epoch 12/20, Train Loss: 0.05410\n",
      "[epoch12] mean_loss: 0.03571: 100%|██████████| 16/16 [00:13<00:00,  1.19it/s]\n",
      "Epoch 13/20, Train Loss: 0.03571\n",
      "[epoch13] mean_loss: 0.02756: 100%|██████████| 16/16 [00:13<00:00,  1.17it/s]\n",
      "Epoch 14/20, Train Loss: 0.02756\n",
      "[epoch14] mean_loss: 0.03085: 100%|██████████| 16/16 [00:14<00:00,  1.10it/s]\n",
      "Epoch 15/20, Train Loss: 0.03085\n",
      "[epoch15] mean_loss: 0.02444: 100%|██████████| 16/16 [00:13<00:00,  1.21it/s]\n",
      "Epoch 16/20, Train Loss: 0.02444\n",
      "[epoch16] mean_loss: 0.05393: 100%|██████████| 16/16 [00:13<00:00,  1.23it/s]\n",
      "Epoch 17/20, Train Loss: 0.05393\n",
      "[epoch17] mean_loss: 0.07335: 100%|██████████| 16/16 [00:13<00:00,  1.20it/s]\n",
      "Epoch 18/20, Train Loss: 0.07335\n",
      "[epoch18] mean_loss: 0.04356: 100%|██████████| 16/16 [00:13<00:00,  1.21it/s]\n",
      "Epoch 19/20, Train Loss: 0.04356\n",
      "[epoch19] mean_loss: 0.09581: 100%|██████████| 16/16 [00:14<00:00,  1.14it/s]\n",
      "Epoch 20/20, Train Loss: 0.09581\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAAHJCAYAAACG+j24AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABr5ElEQVR4nO3deVhU9f4H8PcMMMDIvqug4MKmiAuIJmpiZD9brpq31T3LzLDM3K51rW4uuVxLc8sts8y6pV4rrdSuWakoSIrKrgjKLjszDDBzfn8gkwgiAsOZ5f16nnmAM99z5vPhgLw95zvnSARBEEBERERkoqRiF0BEREQkJoYhIiIiMmkMQ0RERGTSGIaIiIjIpDEMERERkUljGCIiIiKTxjBEREREJo1hiIiIiEwawxARERGZNIYhIiO1cOFC+Pn5NfmIiIho1Wvs27cPfn5+uH79uk7Xaan2fK3WiI+Px7x58/Dggw+iT58+GDlyJN566y1kZmaKXRqRSZDwdhxExikjIwOFhYXarzdu3IjLly/j448/1i6TyWQIDAxs8WsUFhYiIyMDgYGBkMlkOlunpfbt24dFixbh2LFj8PT01OlrtdQXX3yBZcuWISwsDGPHjoWbmxsyMjKwbds2FBUVYefOnejVq5fYZRIZNXOxCyAi3ejSpQu6dOmi/drJyQkymQx9+/Zts9dwcnKCk5OTztcxVrGxsVi6dCmef/55LF68WLs8LCwMI0eOxLhx47Bo0SIcPHhQxCqJjB9PkxGZuOjoaPj5+WHv3r0YMWIEHnjgAfz+++8AgP/85z8YN24c+vbtiz59+uBvf/sbDh06pF33ztNQCxcuxJQpU/Dtt99i1KhR6N27N5544gn8+uuvrVoHAOLi4vD888+jb9++ePDBB7Fr1y5MmTIFCxcubPX3IC8vD4sWLcLw4cPRp08fjB8/HseOHas35uTJk3j66afRr18/hIaG4pVXXsGVK1e0z2dmZmLmzJkICwtDcHAwnn766QY93Gn79u2wtbXFG2+80eA5JycnLFy4EA8//DDKy8sBABMnTsTEiRPrjavbf9HR0QBqv7+BgYH4z3/+g/DwcAwbNgybNm1Cr1696h0pBIA9e/YgMDAQ+fn5AICsrCy88cYbGDhwIIKDgzF58mRcvny5md9FIsPFMEREAIC1a9diwYIFWLBgAfr27YsvvvgC//znPzFy5Ehs2bIFq1atgoWFBebNm4esrKy7bufixYvYvn07Zs+ejQ0bNsDc3ByzZ89GSUlJi9dJS0vDlClTAAD//ve/ERUVhU8++QSxsbGt7rugoADjx4/HmTNnMGfOHKxfvx6dO3fGrFmztEdk6oJOr169sGnTJrz//vu4cuUKXnrpJWg0Gmg0GsyYMQMKhQIrV67Exo0b4eDggFdeeQXXrl1r9HUFQcDvv/+OwYMHw9rautExjzzyCF599VXY2NjcV09qtRqbN2/G+++/j9dffx1PPPEE1Go1fv7553rjvv/+ewwePBiurq4oLCzEM888g0uXLuHtt9/GmjVroNFo8PzzzyMtLe2+Xp/I0PA0GREBAJ555hk88sgj2q8zMzMxbdo0zJo1S7vM09MT48aNw7lz59CpU6dGt1NWVoZ9+/ZpT9HJ5XJMmDABp0+fxqhRo1q0zpYtW2BjY4Nt27Zpg0O3bt3wzDPPtLrvnTt3orCwEIcPH4aXlxcAYPjw4ZgyZQpWrlyJxx57DBcuXEBlZSVmzJgBd3d3AEDHjh1x7NgxKBQKKJVKpKWl4eWXX8bw4cMBAH369MHHH38MlUrV6OsWFRVBpVLpbC7Tyy+/jAcffFD7dWhoKH744Qft9ywrKwvnzp3DypUrAQC7du1CcXExvvzyS3Tu3BkAMGzYMIwePRofffQR1q1bp5M6ifQBwxARAQD8/PzqfV13+qmsrAzp6elIT0/HqVOnAADV1dV33Y6Tk1O9uUoeHh4AAKVS2eJ1Tp8+jeHDh9c7gtKvXz/tH+3WOHPmDPr166cNQnWeeOIJLFq0CFeuXEFwcDAsLS0xfvx4jB49GsOHD0dISAj69OkDAOjQoQN69OiBt99+GydPnsSwYcMQHh6ORYsW3fV1pdLaA/NqtbrVPTTG19e33td/+9vf8PbbbyMvLw9ubm744YcfYG1tjcjISADAqVOnEBAQAHd3d9TU1GhrHDZsGOcskdHjaTIiAgA4OzvX+zojIwNTpkxBaGgonn32WWzdulUbgpp6E+qdp3wkEgkAQKPRtHidwsLCBvUBgKur61232VwlJSVwcXFpsLxuWWlpKTw9PfH5558jODgYX3/9NaZOnYohQ4Zg7dq10Gg0kEgk2LFjB8aOHYvffvsNc+bMwQMPPIDXX38dxcXFjb6ug4MDOnTo0OQpR4VCcdf17+XO79cjjzwCmUyGw4cPA6g9Rfbwww9rv/fFxcX4888/0atXr3qPL774AmVlZU2GWSJDxyNDRNSARqPBSy+9BAsLC3z99dcIDAyEubk5UlNTRTlK4OHhgZs3bzZYfvPmTfj4+LRq2/b29igoKGiwvG5SsaOjI4C/TntVVVUhNjYWX331FTZv3gw/Pz+MHj0a7u7ueOedd7BkyRIkJibixx9/xNatW2Fvb49333230dcODw9HdHQ0VCoVLC0tGzy/b98+LF26FHv27EG/fv0ANDySpFAomtWnjY0NRo4cicOHDyM8PByJiYlYsGCB9nlbW1sMHDgQ8+fPb3R9XV8GgUhMPDJERA0UFRXh6tWrGD9+PPr06QNz89r/N504cQJA00d5dCE0NBQnTpyoN/8mISGhTS6mGBoairi4uAYXODx48CBcXV3RtWtXfPrpp4iIiEBVVRVkMhkGDx6Mf/3rXwCA7OxsxMXF4YEHHsCFCxcgkUgQEBCAOXPmwNfXFzk5OXd97WnTpqG4uBhr165t8NzNmzexbds2dO3aVXs5BBsbmwbbO3fuXLN7/dvf/obz58/jiy++gJubGwYNGqR9buDAgbh69Sp8fHwQFBSkfRw8eBD/+c9/YGZm1uzXITI0PDJERA04Ozujc+fO+OKLL+Dh4QE7Ozv8/vvv2LVrF4Cm5//owssvv4xDhw5h+vTpmDZtGkpLS/HRRx9BIpFoT6k15dtvv4W9vX2D5VOmTMHUqVNx8OBBTJ06Fa+++iocHR1x4MABnD59GsuWLYNUKsWgQYOwevVqzJo1CxMmTICZmRn27t0LmUyGESNGoHPnzrCyssL8+fMRFRUFFxcXnDx5EgkJCZg0adJd6+rbty9ee+01fPjhh0hLS8PYsWPh6OiIlJQU7NixAxUVFfjkk0+0PY4YMQK//PILli5dioceegixsbE4cOBAs7+P4eHhcHJywt69ezFlyhTtvKW678V///tfTJkyBdOmTYOjoyMOHTqEr7/+usm5T0TGgGGIiBq1ceNGLF26FAsXLoRMJkOPHj2wadMmLFu2DDExMQ2ud6NLXbt2xfbt27Fy5UrMnj0bzs7OmDFjBjZt2oQOHTrcc/2NGzc2unzKlClwdXXFl19+iTVr1mDp0qWorq6Gv78/Nm7ciJEjRwIA/P39sXnzZmzYsAFvvPEG1Go1evfujR07dqBbt24AgB07dmi3UVpaCm9vb7z33nsYN25ck7XNnDkTgYGB+OKLL7B8+XIUFxfDw8MDw4YNw8svv1zvXXtPPvkkMjIysH//fnz11VcYOHAgPvroIzz77LPN+j6amZnh0Ucfxa5du/DEE0/Ue87d3R179+7FmjVr8M4770ClUsHb2xtLly7F+PHjm7V9IkPF23EQkd47deoULCwsEBISol1WUlKCIUOGYP78+U0efSEiuhceGSIivXfp0iWsW7cOb7zxBnr16oWioiLs2LEDtra2eOyxx8Quj4gMHMMQEem9adOmoaqqCl9++SWys7Mhl8sxcOBAfPDBB7zPGRG1Gk+TERERkUnjW+uJiIjIpDEMERERkUljGCIiIiKTxgnUzRAXFwdBEGBhYSF2KURERNRM1dXVkEgk2tvZ3A2PDDWDIAhN3piyNdutqqrSybb1jSn1CphWv+zVeJlSv+zVODX37zePDDVD3RGhoKCgNt2uQqFAQkICevToAblc3qbb1jem1CtgWv2yV+NlSv2yV+MUHx/frHE8MkREREQmjWGIiIiITBrDEBEREZk0hiEiIiIyaZxATUREolKr1aiurha1BpVKpf0olRr3cQJj6dXCwgJmZmZtsi2GISIiEoUgCMjJyUFxcbHYpUCj0cDc3BxZWVkGHRCaw5h6dXBwgIeHByQSSau2wzBERESiqAtCbm5ukMvlrf6D1hpqtRoqlQqWlpZtdrRBXxlDr4IgQKFQIC8vDwDQsWPHVm2PYYiIiNqdWq3WBiFnZ2exy4FarQYAWFlZGWxAaC5j6dXa2hoAkJeXBzc3t1b1YtjHx4iIyCDVzREy9ov+kW7V/fy0ds4ZwxAREYlGzFNjZPja6ueHYYiIiIhMGsMQERERmTSGISIiohZauHAh/Pz8mny01MSJE7Fw4cJmj4+IiMD69etb/Hr3cv36dfj5+SE6OlpnryEWvptMRNGXcnH1WgUCAsSuhIiIWmLx4sWYO3eu9uvw8HD84x//wOjRo1u97fXr19/XO6S++eYbWFpatvp1TRHDkIi2HkxAmaIaDw2pRBe+o4KIyODY2trC1ta2wTJXV9dWb9vBweG+xjs5ObX6NU0VT5OJyNXBCgCQklkiciVERPpBEARUqmra/1FVA0EQdNLTvn37EBERgaVLlyIkJAQvv/wyAOCXX37BM888g379+iEoKAjjx4/HyZMntevdfpqsbhv79+9HZGQkevfujSeffBJxcXHa8befJlu/fj0mTpyIrVu3YtiwYQgKCsKkSZNw5coV7fjCwkLMmTMHISEhCAsLw6pVqzBp0qRWnWqrrKzEhx9+iJEjRyIoKAhjxozB0aNHtc+r1WqsWrUKw4cPR+/evfHII4/gyy+/1D5/8+ZNzJ49G2FhYejTpw+eeeYZnDlzpsX1NBePDImou6c9rmSVIfV6CUYOFLsaIiJxCYKABR//joT0QlFe36+LPVbMCtfJtm/cuIHc3Fzs378flZWVuHjxImbNmoV58+Zh1apVqKiowNq1a/Hmm2/i+PHjkMlkDbaRl5eHvXv3YtWqVbCwsMA777yDBQsW4Keffmr0LeZxcXGwtrbGJ598goqKCixYsADvvvsuduzYAY1Gg5kzZ0Kj0WDr1q2QyWRYsWIFzp49i9DQ0Bb3+cYbb+Dy5cv45z//CR8fH/zwww949dVXsWHDBowcORJ79uzBjz/+iLVr18Ld3R3/+9//8M4776Bnz54ICQnBO++8A5VKhc8//xwymQybN2/GK6+8ghMnTuj0mlQMQyLq6WmPI2euI/U6jwwRERm7V155BV5eXgCAhIQEvPXWW3j++ee1z0+aNAnTpk3DzZs3G729RHV1Nd555x0E3JpoOmPGDMyaNQv5+flwc3NrML6mpgYrV67Unm6bOHEiVq1aBQCIjY1FfHw8Dh8+jG7dugEAPvzwQ4wYMaLF/aWlpeHYsWPYvHmzdjuvvvoqkpKSsHnzZowcORIZGRmQy+Xw8vKCq6srJkyYgG7dusHHxwcAkJGRAV9fX3Tp0gWWlpZYvHgxHn/8cZ1fKZthSEQ9PO0BAFezSqFWa2BmxrOWRGS6JBIJPng1HKoqdbu/tlqjhqCu1ulFIL29vbWfBwQEwN7eHlu3bsXVq1eRnp6OhISE2lrUd++/e/fu2s/r5ird7erLLi4u9eYd2draascmJibCzs5OG4QAwNnZWRtKWiIpKQkAMGDAgHrLQ0JCsGbNGgDA888/j6NHj2LYsGHo3bs3hgwZgv/7v//T3pLl1Vdfxbx583DkyBGEhIQgPDwco0eP1vnEcP71FVFHZzksLSRQVWtwLadM7HKIiEQnkUhgZWne/g+Zuc6vhm1lZaX9/OzZsxg1ahTOnz8PX19fzJo1S3vUpimNnT6721ynxsbWMTMz09kcqTtpNBqYm9cee/H29sbPP/+Mbdu2ITQ0FMeOHcPf/vY37N+/HwAQGRmJ3377DcuWLYOHhwe2bduGUaNGISUlRac1MgyJSCqVoLNz7Q9rckaRyNUQEVF72b59O8LCwvDxxx9jypQpGDJkCLKzswHcPdy0JV9fX5SVlSEtLU27rLi4GNeuXWvVNoHaU3C3i4mJQY8ePQAAn332GX7++WcMGTIE8+fPx3fffYfBgwfj0KFDqKqqwvLly5GZmYnRo0fj/fffx5EjRyCVSnH8+PEW19UcPE0mss7OMlzJUSE5owiPDPYWuxwiImoHHTt2xNGjRxETEwMPDw9ER0fjo48+AgBUVVXp/PVDQkIQHByM+fPn4+2334aVlRVWr14NpVJ5zyNkFy5cgEqlqrfMzc0N/v7+GD58ON59910AtUeBfvjhBxw7dgwffvghgNp3i23YsAFWVlbw9/dHWloaLl++jMmTJ0Mmk+H8+fOIiYnB22+/DRcXF/z666+oqKhAv379dPJ9qMMwJLK6I0NJPDJERGQyZs+ejYKCAu3b7Hv06IFly5Zh3rx5uHDhQr25Qbry0Ucf4f3338eUKVNgaWmJ5557DmlpabCwsGhyvdWrVzdY9vjjj2P16tVYu3Yt/v3vf+Ott95CaWkpevbsifXr1yMyMhJA7Zygmpoa/Otf/0JBQQFcXV3x3HPPYcaMGdqali9fjpkzZ6KsrAzdunXDmjVrEBIS0vbfgNtIhPY6aWjA4uPjAQBBQUFtul2FQoGz5y5i9f5sSCTA3vdHQ27V9A+hoVIoFEhISEBAQIBO3x6pL0ypX/ZqvHTZb2VlJa5evQofH596c2nEolarUVlZCSsrK52/c0lsarUa2dnZSEpKwrBhw7Thp6qqCmFhYViyZAnGjBkjbpHNdK+fo+b+/eacIZHZWJvB1cEKggCkXi8WuxwiIjIB5ubmmDt3LtasWYNr164hNTUVS5YsgUwmw7Bhw8Qur90xDOmB7p1r32KfdI2nyoiISPdsbW2xceNG/PnnnxgzZgyeeuopFBQU4LPPPjPJ23pwzpAe6OFlh9OXcpGSWSx2KUREZCLCwsKwd+9escvQCzwypAd68MgQERGRaBiG9EC3TnaQSiUoLK1EQbFS7HKIiNoN38NDrdFWPz8MQ3rAUmYGbw87ALz4IhGZhrorEtfU1IhcCRmyup+fup+nltKrMLRx40ZMnDjxrs+vX78efn5+jT4WLVqkHRcREdHg+TfffLM9Wmixnl0cADAMEZFpMDMzg5mZGUpLS8UuhQxYaWmp9mepNfRmAvWnn36KdevWITQ09K5jpk2bhmeeeabesm+++QabN2/G5MmTAQDl5eXIysrCli1b0KtXL+04fbiORVP8ujjip9PXePFFIjIJEokEbm5uyM7OhqWlJTp06KDze4M1Ra1Wa6+qbArXGTL0XgVBQEVFBUpLS9GxY8dW/+yIHoZyc3OxePFixMbG3vNuuR06dECHDh20X2dkZGDLli1YuHAh/P39AQDJyckQBAH9+/eHnZ2dTmtvS75dHQEAqZnFUGsEmEnF+0eBiKg92NvbQ6lUoqCgAPn5+aLWotFoUFNTA3Nzc0ilenXSpM0ZS68SiQQODg6wt7dv9bZED0OXLl2Cvb09Dh48iA0bNuDGjRvNXnfFihXo2bMnnn76ae2ypKQkuLq6GlQQAgBPN1tYW5pBqVIjM7cM3h0Nq34iovslkUjQsWNHuLm5obq6WtRalEolrly5gi5dusDa2lrUWnTNWHq1sLBosyNbooehiIgIRERE3Pd68fHxOHbsGHbt2lUv2SYnJ0MulyMqKgpxcXFwcnLCuHHjMGnSpFYlYEEQoFAoWrx+Y5RKZb2P3TrZ4dLVIlxMzYWbvei7pk3d2auxM6V+2avxMqV+NRqN9mPd58bKWHq982axjREEoVmn0Az2L+6nn36K4OBgDBo0qN7ylJQUlJWVYfTo0Xj11VcRExOD1atXo6SkBK+99lqLX6+6uhoJCQmtLbtR6enpAABH69pZ8Wfjr6Gj3DgnFdb1aipMqV/2arxMqV/2anxkMtk9xxhkGFIoFDhy5AiWLFnS4LmdO3dCpVLBxsYGAODn54eKigps2rQJUVFRLT46ZGFhgR49erSq7jsplUqkp6fD29sb1tbWKBPy8Pvl8ygolyAgIKBNX0tsd/Zq7EypX/ZqvEypX/ZqnFJTU5s1ziDD0G+//QaNRoPIyMgGz1lYWGjvwFvH19cXCoUCJSUlcHR0bNFrSiQSnd2l2traGnK5HEE93QEA1/PKITWTwcrSIHdPk+p6NRWm1C97NV6m1C97NS7NfZeZQU4jj42NRa9evRpMktZoNIiIiMCmTZvqLY+Pj4eLi0uLg1B7cba3hou9FTS8gz0REVG70eswpFarkZ+fj8rKynrLExMT4evr22C8VCrFqFGjsG3bNhw+fBgZGRn46quvsG3btlbNF2pPPbvUBjZefJGIiKh96HUYys7ORnh4OA4dOlRveUFBARwcHBpdZ+7cuZg+fTrWrFmD0aNHY+fOnVi8eDGeeuqpdqi49fy0YahY3EKIiIhMhF5NSlmxYkW9rz09PZGUlNRg3J3h6Hbm5uaYOXMmZs6c2eb1tYe6iy/yStRERETtQ6+PDJmiHp4OkEqAgmIlCksr770CERERtQrDkJ6xtjRHF97BnoiIqN0wDOkhX06iJiIiajcMQ3rIt4sDACDpGsMQERGRrjEM6aG6I0MpmcXQaASRqyEiIjJuDEN6qIu7LSxlZlCqanA9r0zscoiIiIwaw5AeMjOTooenAwDOGyIiItI1hiE9xYsvEhERtQ+GIT1VN2+IF18kIiLSLYYhPVUXhtKzS1FZVSNyNURERMaLYUhPuThYwcnOEhqNgCs3SsQuh4iIyGgxDOkpiUSCnl68+CIREZGuMQzpMb+6m7by4otEREQ6wzCkx7S35cgsFrcQIiIiI8YwpMd6ejlAIgHyChUoLlOJXQ4REZFRYhjSY3IrC3i62QLgvCEiIiJdYRjSc368gz0REZFOMQzpOe0d7BmGiIiIdIJhSM9p72CfUcQ72BMREekAw5Ce69rRDjILM1RU1iCroFzscoiIiIwOw5CeMzeTontnewCcN0RERKQLDEMGgBdfJCIi0h2GIQPAiy8SERHpDsOQAdDewT6rBFXVapGrISIiMi4MQwbAzdEaDjaWqFHzDvZERERtjWHIAEgkEvS8db0hTqImIiJqWwxDBqLuStS8+CIREVHbYhgyEH9dfLFY3EKIiIiMDMOQgeh5Kwxl36xASTnvYE9ERNRWGIYMhI21BTq72gAAUvgWeyIiojbDMGRA6i6+yEnUREREbYdhyID4ejkA4CRqIiKitsQwZEB8u/51B3tB4B3siYiI2gLDkAHx7mgPC3MpyhTVyL5ZIXY5RERERkGvwtDGjRsxceLEJsfs378ffn5+DR7Xrl3Tjjl8+DBGjx6NoKAgPP744zhx4oSuS28XFuZSdKu7gz1v2kpERNQm9CYMffrpp1i3bt09xyUlJWHgwIH4/fff6z08PT0BAKdPn8a8efPw3HPP4cCBAwgPD8esWbOQlpam6xbaBS++SERE1LbMxS4gNzcXixcvRmxsLHx8fO45Pjk5Gf7+/nB1dW30+a1btyIyMhITJkwAACxYsABxcXHYtWsX3nvvvTatXQy8+CIREVHbEj0MXbp0Cfb29jh48CA2bNiAGzduNDk+KSkJo0aNavQ5jUaDc+fOYeHChfWWh4WF4ciRI62qUxAEKBSKVm3jTkqlst7H5vByswIApN0oRklpOSzM9ebgXpNa0qshM6V+2avxMqV+2atxEgQBEonknuNED0MRERGIiIho1tjCwkIUFBTg7Nmz2L17N4qLixEcHIw333wTPj4+KC0thUKhgIeHR7313NzckJ2d3ao6q6urkZCQ0Kpt3E16enqzxwqCALmlFAqVBsdPxcPTRaaTmnTlfno1BqbUL3s1XqbUL3s1PjLZvf9Oih6G7kdycjIAwMzMDB988AEUCgU2btyI5557Dt999x1qamoANGzc0tISKlXrbmFhYWGBHj16tGobd1IqlUhPT4e3tzesra2bvZ5frApxyQVQWzgiIKBLm9akKy3t1VCZUr/s1XiZUr/s1TilpqY2a5xBhaFBgwbhzJkzsLe31y7bsGEDRowYgX379uHvf/87AKCqqqreeiqVqtU7XCKRQC6Xt2obd2NtbX1f2w7wdkZccgGu5lTorCZdud9eDZ0p9ctejZcp9ctejUtzTpEBevRusua6PQgBgFwuh6enJ3Jzc+Hg4AC5XI68vLx6Y/Ly8hqcOjNkdRdf5NvriYiIWs+gwtCePXsQFhaGyspK7bLy8nKkp6ejR48ekEgk6N+/P86cOVNvvejoaAwYMKC9y9WZuneUZRVUoExRdY/RRERE1BS9DkNqtRr5+fna8DNixAgIgoD58+cjJSUF8fHxiIqKgpOTE8aOHQsAmDp1Kn744Qfs3LkTaWlpWLlyJRISEjB58mQxW2lTtnIZOrp0AMC32BMREbWWXoeh7OxshIeH49ChQwCAjh07YteuXaioqMCzzz6LKVOmwNbWFp999hmsrGrfch4eHo5ly5bhyy+/xNixY3H69Gls3rwZ3bt3F7OVNseLLxIREbUNvZpAvWLFinpfe3p6Iikpqd6ygIAAbN++vcntjBkzBmPGjGnr8vSKbxdHHD93HckMQ0RERK2i10eG6O58uzgAAJJ5B3siIqJWYRgyUN0628PcTILSiirkFrbtlbGJiIhMCcOQgbIwN4NPp1t3sOepMiIiohZjGDJgnERNRETUegxDBowXXyQiImo9hiEDVnfxxbQbJahRa0SuhoiIyDAxDBmwTi4dYGNtgeoaDdKzSsUuh4iIyCAxDBkwiUSiPTrEeUNEREQtwzBk4Hredr0hIiIiun8MQwau7h1lDENEREQtwzBk4OpOk13PK0e5slrkaoiIiAwPw5CBs7exhLuTHACQmsmjQ0RERPeLYcgI8OKLRERELccwZAT+uvhisbiFEBERGSCGISPg63UrDGXyDvZERET3i2HICHTztIeZVILiMhXyi5Ril0NERGRQGIaMgKWFGXw62QGoPTpEREREzccwZCR61k2i5k1biYiI7gvDkJHgxReJiIhahmHISNRdfDH1egnUvIM9ERFRszEMGYnOrjboYGWOqmo1ruWUiV0OERGRwWAYMhJSqQQ9vXjxRSIiovvFMGRE6u5gn8IwRERE1GwMQ0aEt+UgIiK6fwxDRqRuEnVmbhkUlbyDPRERUXMwDBkRRzsruDpaQxCA1OvFYpdDRERkEBiGjIwvL75IRER0XxiGjAwvvkhERHR/GIaMjK82DBWLWwgREZGBYBgyMt097SGVSlBYWomCYt7BnoiI6F4YhoyMlcwc3h61d7DnW+yJiIjujWHICPHii0RERM3HMGSEePFFIiKi5tOrMLRx40ZMnDixyTEpKSl46aWXEBYWhsGDB2P27NnIysqqNyYiIgJ+fn71Hm+++aYuS9crvl1v3cE+sxhqjSByNURERPrNXOwC6nz66adYt24dQkND7zqmqKgIU6dORWhoKD7//HOoVCp88MEHmD59Ovbv3w9LS0uUl5cjKysLW7ZsQa9evbTrWllZtUcbesHTzRbWlmZQqtTIzC2Dd0c7sUsiIiLSW6KHodzcXCxevBixsbHw8fFpcuzRo0ehVCqxYsUKWFpaAgBWrVqF4cOH49y5cxg8eDCSk5MhCAL69+8POzvTDAFmt+5gfyG1AEnXihiGiIiImiD6abJLly7B3t4eBw8eRHBwcJNjBw8ejA0bNmiD0O1KSkoAAElJSXB1dTXZIFTHlxdfJCIiahbRjwxFREQgIiKiWWM9PT3h6elZb9mWLVtgaWmpPb2WnJwMuVyOqKgoxMXFwcnJCePGjcOkSZMglbY8+wmCAIVC0eL1G6NUKut9bEve7nIAwPmUPFRUVEAikbT5a9wPXfaqj0ypX/ZqvEypX/ZqnARBaNbfP9HDUGt89tln2LNnDxYtWgRnZ2cAtROsy8rKMHr0aLz66quIiYnB6tWrUVJSgtdee63Fr1VdXY2EhIS2Kr2e9PT0Nt+mRY0GMnMJcguVOPzrn/Bx1485U7roVZ+ZUr/s1XiZUr/s1fjIZLJ7jjHIMCQIAj766CNs2rQJM2bMwJQpU7TP7dy5EyqVCjY2NgAAPz8/VFRUYNOmTYiKimrx0SELCwv06NGjLcrXUiqVSE9Ph7e3N6ytrdt02wAw9KoEx2JuIDXfHKMfDGjz7d8PXfeqb0ypX/ZqvEypX/ZqnFJTU5s1zuDCUHV1NRYtWoTvv/8e8+fPxwsvvFDveQsLC1hYWNRb5uvrC4VCgZKSEjg6OrbodSUSCeRyeYvrboq1tbVOtv1YeA8ci7mB6Et5qBlvDrsO907HuqarXvWVKfXLXo2XKfXLXo1Lc6eIiD6B+n7Nnz8fP/74I9asWdMgCGk0GkRERGDTpk31lsfHx8PFxaXFQchQ9fByQLfO9qhRa/C/2EyxyyEiItJLeh2G1Go18vPzUVlZCQDYt28fDh06hDlz5mDgwIHIz8/XPiorKyGVSjFq1Chs27YNhw8fRkZGBr766its27atVfOFDNkjg7oCAH46nQ5B4AUYiYiI7qTXYSg7Oxvh4eE4dOgQAOD7778HAKxcuRLh4eH1HnVj5s6di+nTp2PNmjUYPXo0du7cicWLF+Opp54SrQ8xDe/vCUuZGTJzy5GQXih2OURERHpHr+YMrVixot7Xnp6eSEpK0n69Y8eOe27D3NwcM2fOxMyZM9u8PkMkt7LAsL6dceRMBn46fQ2BPs5il0RERKRX9PrIELWNh2+dKvv9zxsoV1SJXA0REZF+YRgyAX5dHOHd0Q5VNRocP3dd7HKIiIj0CsOQCZBIJBilnUh9jROpiYiIbsMwZCIe7O8JmbkU6dmlvF8ZERHRbRiGTISNXIbwvp0B1B4dIiIioloMQybk4bDaU2Un/rwBRWW1yNUQERHpB4YhExLo4wQvdxuoqtT4lROpiYiIADAMmRSJRIKHw7wBAD9F81QZERERwDBkciJCvGBuJkXa9RKkZhaLXQ4REZHoGIZMjF0HGR7o0xEAjw4REREBDEMm6ZFB3gCAX89lQqmqEbcYIiIikTEMmaDe3Z3RyaUDlCo1fvvzhtjlEBERiYphyATVvyJ1urjFEBERiYxhyERFhHSBuZkEyRnFuJpVInY5REREomEYMlEOtpYI631rIjWvSE1ERCaMYciEjbp1RerjsZmorOJEaiIiMk0MQyYsuKcr3J3kqKiswR/ns8Quh4iISBQMQyZMKpVo71fGU2VERGSqGIZM3EMDu0AqlSAhvRDXckrFLoeIiKjdMQyZOCc7KwwMdAcA/MwrUhMRkQliGCKMunVF6l/OZqKqWi1uMURERO2MYYjQz88Nro7WKFdW4+QFTqQmIiLTwjBEMJNKEDnw1kRqniojIiITwzBEAIDIgV0glQAX027iel6Z2OUQERG1G4YhAgC4OFhjQEDdROoMkashIiJqPwxDpFV3RepjZzNQXcOJ1EREZBoYhkgrJMAdTnZWKK2owumLOWKXQ0RE1C4YhkjLzEyKyLAuAICfTqeLWwwREVE7YRiieh4e2BUSCXA+pQDZBRVil0NERKRzDENUj5uTHP383ADwitRERGQaGIaogbqJ1EfPZqBGrRG5GiIiIt1iGKIGBvbygIOtJYrLVDhziROpiYjIuDEMUQPmZlI8FHprIjVPlRERkZFjGKJGPXzrVFlcUh5yCxUiV0NERKQ7ehWGNm7ciIkTJzY5pqioCHPnzkVoaChCQ0Px9ttvQ6Go/8f68OHDGD16NIKCgvD444/jxIkTuizbKHV06YDgni4QBODIGR4dIiIi46U3YejTTz/FunXr7jlu9uzZyMzM1I7/448/8O6772qfP336NObNm4fnnnsOBw4cQHh4OGbNmoW0tDRdlm+URg3yBgAcic6AmhOpiYjISLVZGLpw4QJ+/vlnlJaW3td6ubm5mD59Oj766CP4+Pg0OTYuLg5nzpzB8uXL0atXLwwePBjvvfce/vvf/yI3NxcAsHXrVkRGRmLChAno3r07FixYgF69emHXrl0t7s1UDertAbsOMhSWViI2MU/scoiIiHSiRWEoPz8fkyZNwoYNGwAAn332GZ5++mnMnj0bDz/8MFJSUpq9rUuXLsHe3h4HDx5EcHBwk2NjYmLg6uqK7t27a5cNHDgQEokEsbGx0Gg0OHfuHAYNGlRvvbCwMMTExNxHhwQAFuZmGHlrIvWPvCI1EREZKfOWrLRy5UpcuXIFL774IjQaDT755BM88MADmDdvHt5//32sWbMGmzdvbta2IiIiEBER0ayxubm56NixY71lMpkMDg4OyM7ORmlpKRQKBTw8POqNcXNzQ3Z2dvOauwtBEBrMTWotpVJZ76M+GtbHDfuPpyImIReZ2YVwtrdq0XYMode2ZEr9slfjZUr9slfjJAgCJBLJPce1KAz9/vvv+Mc//oGhQ4fi3LlzKCgowNKlS+Hv74/p06fjzTffbMlm70mpVEImkzVYbmlpCZVKhcrKSgBoMKbu+daorq5GQkJCq7ZxN+np6TrZblvp6ibDtbwqfP3TeTwYZNeqbel7r23NlPplr8bLlPplr8ansdxwpxaFoduPvvz666+QyWTaU1MymQyCILRks/dkZWWFqqqqBstVKhXkcjksLS0BoMEYlUoFa2vrVr22hYUFevTo0apt3EmpVCI9PR3e3t6trk+XHq9ywMffXER8RhVmjPeHVHrvlH0nQ+m1rZhSv+zVeJlSv+zVOKWmpjZrXIvCkLe3N2JiYhAcHIwff/wRAwcO1AaRgwcPwtvbuyWbvScPDw8cPXq03rKqqioUFxfD3d0dDg4OkMvlyMurP9k3Ly+vwamz+yWRSCCXy1u1jbuxtrbW2bbbwogQb3z6QxJullQiMbMcIQHuLd6Wvvfa1kypX/ZqvEypX/ZqXJpzigxo4QTqGTNm4OOPP8bgwYORmZmJqVOnAgD+/ve/4+DBg3jhhRdastl7Cg0NRU5ODq5d++u6N9HR0QCA/v37QyKRoH///jhz5ky99aKjozFgwACd1GQKZBZmiAjxAgD8xInURERkZFp0ZGj06NFwd3dHbGwsBg4ciL59+wIAQkJCMHv2bAwdOrRNilOr1SgsLIStrS2srKwQHByM/v37Y86cOXjnnXegUCiwZMkSjBkzBu7utUcrpk6dipdeegmBgYEYNmwYvv32WyQkJGDp0qVtUpOpenhQVxz87QrOXM5FYWklnOxaNpGaiIhI37T4OkMDBgzASy+9pA1CNTU1mDFjRpsFIQDIzs5GeHg4Dh06BKD2cNfHH38MT09PTJ48Ga+//jqGDRuGd955R7tOeHg4li1bhi+//BJjx47F6dOnsXnz5npvx6f719XDDgHeTtBoBBw9kyF2OURERG2mRUeGampqsHnzZnTp0gVPPPEETp06hddeew1lZWUYOHAg1q1bB3t7+/ve7ooVK+p97enpiaSkpHrLnJ2d73ml6jFjxmDMmDH3/frUtFGDuiIhvRA/R1/D+IieLZpITUREpG9adGRo/fr12LRpE8rKygAAy5Ytg6OjIxYtWoSMjAysWbOmTYsk/TAkuBM6WJkjt1CB8yn5YpdDRETUJloUhr7//nu88cYbeP7553HlyhWkpKRg5syZmDRpEubMmYNffvmlreskPWAlM8eDA25NpI7mzVuJiMg4tCgM5eXlaW+dceLECUilUgwbNgxA7dvf644YkfEZNagrACD6YjaKy1p3IUsiIiJ90KIw5ObmhuvXrwMAjhw5goCAADg5OQGovZlqa6/pQ/rLp5M9fLs4oEYt4JcYTqQmIiLD16Iw9MQTT2D58uV44YUXEBsbiyeffBIAsHTpUqxfvx6PP/54mxZJ+mXUIG8AwE+nr+nsauNERETtpUVhaPbs2Zg2bRokEgnmzp2L5557DgAQHx+PadOm4ZVXXmnTIkm/DO3bGdaWZsgqqMDFtJtil0NERNQqLXprvUQiwYwZMzBjxox6y/fu3dsmRZF+s7Y0x7B+nvjp9DX8dPoagnq4iF0SERFRi7UoDAFAYWEhdu7ciejoaJSWlsLR0REhISGYMmUKnJ2d27JG0kMPh3XFT6ev4VR8FsqVfWBjbSF2SURERC3SotNkOTk5GDt2LD799FNYWloiMDAQ5ubm2LlzJ8aMGYPc3Ny2rpP0TE8vB3T1sEVVjQa/xV0XuxwiIqIWa1EYWrVqFczNzXHo0CHs3r0b//73v7F7924cPnwYVlZWWLt2bVvXSXpGIpHgoYG1b7M/wttzEBGRAWtRGPr9998xe/ZseHl51Vvu5eWFWbNm4cSJE21SHOm3EQM8YSaVICWzGOnZpWKXQ0RE1CItCkNqtRqOjo6NPufk5ITy8vJWFUWGwd7GEgN71V5TijdvJSIiQ9WiMOTn54f//ve/jT534MAB+Pr6tqooMhyRA7sAAP4Xm4nqGo3I1RAREd2/Fr2b7JVXXsELL7yA4uJiPP7443BxcUFBQQG+++47nDx58p53lSfj0d/PDU52ligsVeHs5Rw80KeT2CURERHdlxaFoSFDhuCDDz7AqlWr8Mcff2iXu7i4YPny5YiMjGyzAkm/mZlJERHSBd/8koIjZzIYhoiIyOC06DQZAPztb3/Db7/9hh9++AF79uzBDz/8gN9++w2urq5YtGhRW9ZIeu6hW6fKziXm4maJUuRqiIiI7k+LwxBQ+/bq7t27o3///ujevTskEglSU1Nx4MCBNiqPDEFnVxsE+jhBIwC/xGSKXQ4REdF9aVUYIqpTN5H66JkM3ryViIgMCsMQtYkhwZ1hJau9eevlq4Vil0NERNRsDEPUJqwtzTG0b2cAvOYQEREZFoYhajN1E6l/P38DispqkashIiJqnma/tX7SpEnNGpeTk9PiYsiwBXg7obNrB9zIr8Af57MQGdZV7JKIiIjuqdlHhgRBaNbD3d0dISEhuqyZ9BRv3kpERIao2UeGdu/ercs6yEhEhHhh9+EEJKQX4npeGTzdbMUuiYiIqEmcM0RtysnOCgP83QBwIjURERkGhiFqc3XXHPolJhNqNW/eSkRE+o1hiNpcSIAH7G1kKCpTITYpT+xyiIiImsQwRG3OwlyKB/t7AeCpMiIi0n8MQ6QTdafKzlzKQXGZSuRqiIiI7o5hiHSia0c79PRygFoj4Pg53ryViIj0F8MQ6Uzd0aGfo3nzViIi0l8MQ6QzQ/t5QmYuRWZuGdJulIpdDhERUaMYhkhnbKwt8ECfTgCA/527IXI1REREjWMYIp2qu3nrHxdyUVXDaw4REZH+ET0MaTQarFu3DkOHDkVwcDCmTZuGa9euNTp2/fr18PPza/SxaNEi7biIiIgGz7/55pvt1RLdJqi7C9yc5FCqapCQqRS7HCIiogaafW8yXdm4cSP27t2L5cuXw93dHatWrcKLL76I77//HjKZrN7YadOm4Zlnnqm37JtvvsHmzZsxefJkAEB5eTmysrKwZcsW9OrVSzvOyspK981QA1KpBA+FdsGenxIRd0WBZ+69ChERUbsS9chQVVUVduzYgaioKAwfPhz+/v5Yu3YtcnNzceTIkQbjO3ToAFdXV+1DqVRiy5YtWLhwIfz9/QEAycnJEAQB/fv3rzfW1pY3DBXLyBAvSCRAeq4KeUU8OkRERPpF1DCUmJiIiooKDBo0SLvMzs4OgYGBOHv27D3XX7FiBXr27Imnn35auywpKQmurq6ws7PTSc10/9yc5Ajq5gQAOH4uS+RqiIiI6hP1NFlOTg4AoGPHjvWWu7m5ITs7u8l14+PjcezYMezatQtS6V+ZLjk5GXK5HFFRUYiLi4OTkxPGjRuHSZMm1Rt3vwRBgEKhaPH6jVEqlfU+GrMHerviQloh/nfuBsaP6AapVCJ2STplSvuWvRovU+qXvRonQRAgkdz7742oYahuR9w5N8jS0hIlJSVNrvvpp58iODi43lElAEhJSUFZWRlGjx6NV199FTExMVi9ejVKSkrw2muvtbjW6upqJCQktHj9pqSnp+tku/rE2UqAlYUEhaUqHDr+J7p3NI05XKawb+uwV+NlSv2yV+NzZ8ZojKhhqG5Sc1VVVb0JziqVCtbW1nddT6FQ4MiRI1iyZEmD53bu3AmVSgUbGxsAgJ+fHyoqKrBp0yZERUW1+OiQhYUFevTo0aJ170apVCI9PR3e3t5N9msMlEolgryLcTalAmkFZngsIkDsknTK1PYtezVOptQvezVOqampzRonahiqOz2Wl5eHLl26aJfn5eVpJ0Q35rfffoNGo0FkZGSD5ywsLGBhYVFvma+vLxQKBUpKSuDo6NiiWiUSCeRyeYvWvRdra2udbVuf9OveAWdTKnA2IR9qmMNWfu+0buhMZd8C7NWYmVK/7NW4NOcUGSDyBGp/f3/Y2NggOjpau6y0tBSXL19GSEjIXdeLjY1Fr169GkyS1mg0iIiIwKZNm+otj4+Ph4uLS4uDELWNjo4W6Ophg+oaDU6cuy52OURERABEDkMymQwTJkzA6tWrcezYMSQmJmLOnDnw8PBAZGQk1Go18vPzUVlZWW+9xMRE+Pr6NtieVCrFqFGjsG3bNhw+fBgZGRn46quvsG3btlbNF6K2IZFIMKJ/ZwDAkbMZIldDRERUS/SLLs6ePRs1NTV46623UFlZidDQUGzfvh0ymQzXr1/HyJEjsXz5cowbN067TkFBAYKDgxvd3ty5c2FnZ4c1a9YgJycHnp6eWLx4MZ566qn2aomaEB7sgc9/SkHa9RJcuVGCbp3txS6JiIhMnOhhyMzMDPPmzcO8efMaPOfp6YmkpKQGyw8dOnTX7Zmbm2PmzJmYOXNmm9ZJbcNWLkNYbw/8cT4LR89m4KXOQWKXREREJk70e5OR6Ym8dfPW47GZqK5Ri1wNERGZOoYhand9fd3gbG+FMkU1oi/liF0OERGZOIYhandmUglGhtYeHTpyhhOpiYhIXAxDJIqRoV4AgLikPOTz5q1ERCQihiESRScXG/Tu7gxBAH6J5dEhIiISD8MQiaZuIvXRMxnQaASRqyEiIlPFMESieSCoE6wtzZFzU4FLV2+KXQ4REZkohiESjZWlOYb1q70i9VFOpCYiIpEwDJGoHrp1quz381lQVFaLXA0REZkihiESlV8XR3i526CqWo3f/rwhdjlERGSCGIZIVBKJBA+FdgXAaw4REZE4GIZIdCNCPCGVSpB0rQgZOaVil0NERCaGYYhE52hrhdAAdwDA0bOZIldDRESmhmGI9ELdNYf+F5OJGrVG5GqIiMiUMAyRXhgQ4A4HW0sUl6sQk5ArdjlERGRCGIZIL5ibSRExoPZ+ZbzmEBERtSeGIdIbddccOpuQi6LSSpGrISIiU8EwRHrDy90W/l0dodEI+F8sJ1ITEVH7YBgivfLQwL+uOSQIvHkrERHpHsMQ6ZWhfTvBUmaG63nlSLpWJHY5RERkAhiGSK/IrSwwpE8nALwiNRERtQ+GIdI7ddcc+u3P61CqakSuhoiIjB3DEOmdXt2c0dGlA5QqNdZ+eQ5qXoSRiIh0iGGI9I5EIkHUU31hbibFqfhsbPjmPCdTExGRzjAMkV4K6u6C+RMHQCqpnTv02aEEsUsiIiIjxTBEemtwUCfM+ntfAMA3v6Rg//FUcQsiIiKjxDBEeu3hsK6Y/GggAGDHd5dw7CzfYUZERG2LYYj03pMjemDM8O4AgHVf/4kzl3JEroiIiIwJwxDpPYlEgmmP98LIUC9oNAI++OwsLqYViF0WEREZCYYhMggSiQRRf++LsF4eqKrR4F87onHlRonYZRERkRFgGCKDYWYmxbyJIejVzRmKyhos2XoK2QUVYpdFREQGjmGIDIqlhRnenhYGn052KC5T4e0tJ1FYWil2WUREZMAYhsjgdLC2wLsvDkZH5w7ILVRgySenUK6oErssIiIyUAxDZJAc7azw3ozBcLS1RHp2Kd7bHo3KKt7HjIiI7p/oYUij0WDdunUYOnQogoODMW3aNFy7du2u4/fv3w8/P78Gj9vXOXz4MEaPHo2goCA8/vjjOHHiRHu0Qu3Mw7kD3n1pMDpYmSMhvRAffBaDGt7HjIiI7pPoYWjjxo3Yu3cv3n//fXz11VeQSCR48cUXUVXV+GmPpKQkDBw4EL///nu9h6enJwDg9OnTmDdvHp577jkcOHAA4eHhmDVrFtLS0tqzLWonPp3s8fYLgyCzMENMQi7WfRUHjYb3MSMiouYTNQxVVVVhx44diIqKwvDhw+Hv74+1a9ciNzcXR44caXSd5ORk+Pv7w9XVtd7DzMwMALB161ZERkZiwoQJ6N69OxYsWIBevXph165d7dkataNe3ZyxcFIIpFIJ/hd7Hdu/u8gbuxIRUbOZi/niiYmJqKiowKBBg7TL7OzsEBgYiLNnz+LRRx9tsE5SUhJGjRrV6PY0Gg3OnTuHhQsX1lseFhZ213DVXIIgQKFQtGobd1IqlfU+GjNd99rL2w6vjO2Fj7+9iIMnrkAuk2LscB+dvFZzcN8aJ1PqFTCtftmrcRIEARKJ5J7jRA1DOTm1t1Xo2LFjveVubm7Izs5uML6wsBAFBQU4e/Ysdu/ejeLiYgQHB+PNN9+Ej48PSktLoVAo4OHh0azt3Y/q6mokJOjmzunp6ek62a4+0mWvLpbAqP72+OlcCfYeTUV5aQFCetjo7PWag/vWOJlSr4Bp9ctejY9MJrvnGFHDUF0qvbNQS0tLlJQ0vLpwcnIyAMDMzAwffPABFAoFNm7ciOeeew7fffcdampq7ro9lUrVqlotLCzQo0ePVm3jTkqlEunp6fD29oa1tXWbblvftFevAQGA3DYV+3+9ih/OFqOnTxcM6u2us9e7G+5b42RKvQKm1S97NU6pqanNGidqGLKysgJQO3eo7nMAUKlUje6gQYMG4cyZM7C3t9cu27BhA0aMGIF9+/bh73//u3Z7t7vb9u6HRCKBXC5v1TbuxtraWmfb1jft0evUx4OgrBLw46l0rP/mIpwdbBDs66rT17wb7lvjZEq9AqbVL3s1Ls05RQaIPIG67vRYXl5eveV5eXkNTnXVuT0IAYBcLoenpydyc3Ph4OAAuVx+X9sj4yORSPDyuD4Y0qcTatQaLP00GimZRWKXRUREekrUMOTv7w8bGxtER0drl5WWluLy5csICQlpMH7Pnj0ICwtDZeVft18oLy9Heno6evToAYlEgv79++PMmTP11ouOjsaAAQN01wjpHTOpBHOf74/gni5QqtR4Z+tpZOaWiV0WERHpIVHDkEwmw4QJE7B69WocO3YMiYmJmDNnDjw8PBAZGQm1Wo38/Hxt+BkxYgQEQcD8+fORkpKC+Ph4REVFwcnJCWPHjgUATJ06FT/88AN27tyJtLQ0rFy5EgkJCZg8ebKYrZIILMzN8I8pA9HTywGlFVX45yenkF9k/O+eICKi+yP6RRdnz56N8ePH46233sKzzz4LMzMzbN++HTKZDNnZ2QgPD8ehQ4cA1J5W27VrFyoqKvDss89iypQpsLW1xWeffaadcxQeHo5ly5bhyy+/xNixY3H69Gls3rwZ3bt3F7NNEoncygJLpg9CZ1cbFBQrsWTrSZRW8D5mRET0F1EnUAO17wybN28e5s2b1+A5T09PJCUl1VsWEBCA7du3N7nNMWPGYMyYMW1ZJhkwextLvDdjMBas/w2ZueV4d9spvP/yEFhbiv7jT0REekD0I0NE7cHNUY73ZjwAW7kMyRnFWPbpGVTXqMUui4iI9ADDEJkML3dbvPPiIFjJzPBncj5WfxHLQERERAxDZFp8uzjiH1MGwtxMgpMXsvHW5pMoKW/dBTmJiMiwMQyRyenn54Yl0wehg5U5Ll8txLx1v/Ft90REJoxhiExSX183rJo9DO5OcmTfrMC89b/hfHK+2GUREZEIGIbIZHm522LNa8MQ4O2ECmU1lmw9hZ9Op4tdFhERtTOGITJp9jaWeP/lBzC8nyfUGgEf/+c8dnx3CWqNIHZpRETUThiGyOTJLMww9/n+eG6UPwBg//FULP/0DCpVNSJXRkRE7YFhiAi1N3d99mE/zJswABbmUkRfysGCDb/jZglv30FEZOwYhohuM6yfJ5bNHAJ7Gxmu3CjBGx+eQOr1YrHLIiIiHWIYIrqDv7cTVs8eBi93WxSWVmLhht9x+mK22GUREZGOMAwRNcLDuQNWRQ1FP19XqKrUWPbpGew/ngpB4MRqIiJjwzBEdBcdrGvveP9/D3hDEIAd313Chm/Oo0atEbs0IiJqQwxDRE0wM5Ni5rg+ePFvvSGVAD+dvoZ3tp5CuaJK7NKIiKiNMAwR3YNEIsETw7rjrWlhsLY0w/mUAsxb/xuyCyrELo2IiNoAwxBRM4UGeuCDV4fCxd4K1/PKMfejE7h05abYZRERUSsxDBHdB59O9ljz+nD08HJAmaIKb20+if/FZopdFhERtQLDENF9crKzwvJXhuCBPh1Ro9bg33vO4fPDCdDwFh5ERAaJYYioBaxk5lgwMRTjI3oCAL46mozVX8RCVa0WuTIiIrpfDENELSSVSjD50UC89nRfmJtJ8NufN7B40x8oKqsUuzQiIroPDENErfTQwK54b8YDsLG2QNK1Irz50Qlk5JaLXRYRETUTwxBRGwjq7oLVrw1DJ5cOyCtS4p9bzyA1m0eIiIgMAcMQURvp7GqD1a8NQ+/uzlCq1Pjy1wLEJuWLXRYREd0DwxBRG7KVy/DeSw8grJcb1BpgzZfncSo+S+yyiIioCQxDRG3MwlyK1/4ehN5draFWC1jxWQx++/OG2GUREdFdMAwR6YCZmRTjBjthaHBHaDQCVn8eg+O8OCMRkV5iGCLSEalUglfG9ULkwC7QCMC/vzyHY2czxC6LiIjuwDBEpENSqQSv/r0vHhnsDUEAPvoqDj+dviZ2WUREdBuGISIdk0oleOXJPngs3AeCAHz8nz9x6ORVscsiIqJbGIaI2oFEIsFLY4IwZnh3AMCmby/g4Ik0kasiIiKAYYio3UgkEkx7vJf2fmZb/3sR+/6XKnJVRETEMETUjiQSCSaNDsAzkX4AgJ3fX8LXR5NFroqIyLQxDBG1M4lEgucf8cfzj/gDAHYfTsCXPyVCEASRKyMiMk2ihyGNRoN169Zh6NChCA4OxrRp03Dt2t3fbZOSkoKXXnoJYWFhGDx4MGbPno2srPpX+I2IiICfn1+9x5tvvqnrVojuyzORfpj8aCAAYM/PSfj8RwYiIiIxiB6GNm7ciL179+L999/HV199BYlEghdffBFVVVUNxhYVFWHq1Kno0KEDPv/8c2zduhVFRUWYPn06VCoVAKC8vBxZWVnYsmULfv/9d+1jyZIl7d0a0T2Nj+iJF57oDQD4+mgyPv3+MgMREVE7EzUMVVVVYceOHYiKisLw4cPh7++PtWvXIjc3F0eOHGkw/ujRo1AqlVixYgV69uyJ3r17Y9WqVUhLS8O5c+cAAMnJyRAEAf3794erq6v2YWtr297tETXLmOHd8fLYIADAvuOp2PbfiwxERETtSNQwlJiYiIqKCgwaNEi7zM7ODoGBgTh79myD8YMHD8aGDRtgaWnZ4LmSkhIAQFJSElxdXWFnZ6e7wona2KPh3TBrfDAA4OBvV7Bp3wVoNAxERETtwVzMF8/JyQEAdOzYsd5yNzc3ZGdnNxjv6ekJT0/Pesu2bNkCS0tLhIaGAqg9MiSXyxEVFYW4uDg4OTlh3LhxmDRpEqTSlmc/QRCgUChavH5jlEplvY/GzJR6BVrW77BgN6hrArHlv5dx+GQ6VKpqvPhEAKRSia7KbBOmtG9NqVfAtPplr8ZJEARIJPf+N1TUMFS3I2QyWb3llpaW2iM9Tfnss8+wZ88eLFq0CM7OzgBqJ1iXlZVh9OjRePXVVxETE4PVq1ejpKQEr732Wotrra6uRkJCQovXb0p6erpOtquPTKlX4P779ZADYwY54sDpIvwSewOFRUV4YqCj3gciwLT2rSn1CphWv+zV+NyZMRojahiysrICUDt3qO5zAFCpVLC2tr7reoIg4KOPPsKmTZswY8YMTJkyRfvczp07oVKpYGNjAwDw8/NDRUUFNm3ahKioqBYfHbKwsECPHj1atO7dKJVKpKenw9vbu8l+jYEp9Qq0rt+AAMDLMwcff3sRf15RoIONHWaN6wUzM9Hf79AoU9q3ptQrYFr9slfjlJravAvbihqG6k6P5eXloUuXLtrleXl58Pf3b3Sd6upqLFq0CN9//z3mz5+PF154od7zFhYWsLCwqLfM19cXCoUCJSUlcHR0bFGtEokEcrm8Revei7W1tc62rW9MqVeg5f1GDuoGudwKq3bH4I8LOZBIpJj7/ACY62kgAkxr35pSr4Bp9ctejUtzTpEBIk+g9vf3h42NDaKjo7XLSktLcfnyZYSEhDS6zvz58/Hjjz9izZo1DYKQRqNBREQENm3aVG95fHw8XFxcWhyEiMQwpE8nLJwcCnMzCX4/n4WVu2NQXaMRuywiIqMjahiSyWSYMGECVq9ejWPHjiExMRFz5syBh4cHIiMjoVarkZ+fj8rKSgDAvn37cOjQIcyZMwcDBw5Efn6+9lFZWQmpVIpRo0Zh27ZtOHz4MDIyMvDVV19h27ZtrZovRCSWQb07YvHUMFiYS3EqPhsrdp1FdY1a7LKIiIyK6MfcZ8+ejfHjx+Ott97Cs88+CzMzM2zfvh0ymQzZ2dkIDw/HoUOHAADff/89AGDlypUIDw+v96gbM3fuXEyfPh1r1qzB6NGjsXPnTixevBhPPfWUaD0StUZIgDvemhYGmbkUZy7n4P2dZ6CqZiAiImoros4ZAgAzMzPMmzcP8+bNa/Ccp6cnkpKStF/v2LHjntszNzfHzJkzMXPmzDatk0hM/f3c8M/pg/CvHdE4l5iH97dHY+7zA+Bg2/CaW0REdH9EPzJERM0T3NMV70wfBCuZGf5MycfUf/2EVZ/H4NKVm7xiNRFRK4h+ZIiImq93dxcsnTkEW/ZfQHJGMU7E3cCJuBvo6mGL/xvsjREhXpBbWdx7Q0REpMUwRGRgfLs4Ys1rw5GaWYzDp9Jx/Nx1XMspw+b98fj0h8t4cIAXRj/gDZ9O9mKXSkRkEBiGiAxUDy8HRHn1xdTHe+GXmAwcPpmO63nl+PFUOn48lQ7/ro74vwd8EB7cCTILM7HLJSLSWwxDRAbOxtoCTwztjsfDu+Fi2k0cOnkVp+KzkXitCInXirDtvxfx0MAu+L/B3ujo0kHscomI9A7DEJGRkEgkCOrhgqAeLigqrcTPZ67hx1PXUFCsxP7jqdh/PBX9/dzwfw94IzTAXW9v70FE1N4YhoiMkKOdFZ5+yA/jI3wRczkHh06lIy4pD+duPVzsrTBqsDceDusKJzure2+QiMiIMQwRGTEzqQRhvTsirHdH5NyswI+n0nHkTAYKSirxxY+J2PtzEgYFdcToB7wR1N2l2ffxISIyJgxDRCbCw7kDpjzWC8+N8sfJC1k4dDIdCemF+ON8Fv44nwVPNxv832BvRIR2gY01355PRKaDYYjIxMgszPDgAC88OMALV7NKcPhkOo6fy8T1vHJs/e9F7DqUgPDgTggJcEdwT1fYdZCJXTIRkU4xDBGZMJ9O9nhlfDCmPBaI4+eu4/DJdKRnl+KXmEz8EpMJiQTo4emAfn5u6OvrCv+uTrAw58RrIjIuDENEBLmVBUY/4IP/G+yNhPRCnIrPRlxSHq7llCElsxgpmcX4+mgyrGRmCOrhgn6+bujn54rOrjZil05E1GoMQ0SkJZFIEOjjjEAfZwDAzRIl/kzOR1xSPv5MyUNJeRXOXs7F2cu5AABXR2sEdXOCs7USXl2rIZeLWT0RUcswDBHRXTnbW2NkaBeMDO0CjUZAenYp4pLyEJech0tXCpFfpMQvsTcAAN/8cRw9vRzQ19cN/Xxd4cdTakRkIBiGiKhZpFIJunW2R7fO9ngyoicqq2pw6cpNnL2UhTOXspBfUoPkjGIkZ9SeUrO2NENQd1f083NFPz83dHLpwLfuE5FeYhgiohaxkpljgL87ArrYItRbA/fOPkjKLK93Su3M5RycuZwDAHBztEY/Pzf083VDn54usJXzXWpEpB8YhoioTTjZWWFkqJP2lNrVrBLEJecjLikPl68WIq9IiZ9OX8NPp69BIgG6d7ZHcE9XBPd0RYCPE6xk/OeIiMTBf32IqM1JpRJ093RAd08HjI/oiUpVDS5euYm45DzEJeUjM7cMqddLkHq9BN/+LxXmZlIE+jihT08XBPd0RU9PB947jYjaDcMQEemclaU5QgLcERLgDqD2XWoXUgtwPiUf55PzUVBSiQupBbiQWoDPDydCbmWOoO4ut44cucDL3ZbzjYhIZxiGiKjdOdtbY8QAL4wY4AVBEJBVUIE/k/NxPiUfF1ILUKGsRvSlHERfqp1v5GRniT49XRHco/a0mqujtU7r02gEFJerkF+kQF6RUvsxu6AMRcVlCC+UI3KQDxxteZNbImPAMEREopJIJOjsaoPOrjZ4dIgP1BoBV24U43xKAc4n5+Py1ZsoLFXheOx1HI+9DgDo7NpBO9+oTw8X2NznZOwatQYFxUrkFymRVy/w1H5eUKxEdY3mrutf/TEZX/ycgv5+bogI8UJYLw/ILMxa9X0gMkXX88pwPPY6Orl2QERIF9HqYBgiIr1iJpWgp5cjeno5YnxET1RVq5GQXlh7Si0lH6mZxbiRX4Eb+RU4dDIdUgnQzdMBfW+dUgvwcYagEe4IObWhpy78FJZWQhCarkMqqZ0U7uooh6ujNdwc5XDoYIYbWTlIyRWQer0EMQm5iEnIRQdrCwzt2xkRA7zg7+3IU3pETaiuUeNUfDZ+PHUN8WkFAGqP/jIMERHdhczCTHsUCADKldWITy3AhZR8/JmSj+t55UjNLEZqZjG++SUFUqkEGs09kg4AC3MpXB1qQ46rozVcHeVwc/zraxcHa5jfMYlboVAgIaEcU8YE4GaZGv+LzcT/Yq+joFiJH0+l48dT6ejk0gERIbWnAN2ceEluojpZBeX46dQ1HD2bgdKKKgC1/+kYEOCOpx/yFbU2hiEiMig21hYYHNQRg4M6AqidjF171Kh2QvbNkkoAQAcr81sBpzbk3Bl47G0sIZW2/AiOl7stJo0OxIRHAhCfVoBfYjJx8kIWsgoq8PmPifj8x0QEdXdBRIgXHujTEXIrizbpn8iQ1Kg1iL6Yg8OnruJ8SoF2uZOdFR4O64qHw7rqfA5gczAMEZFBc7a3RkRIF0SEdIEgCCgoroTcyhwdrNsnfEilEu2Rq5fH9cGp+CwcO5uJ+LQC7WPz/gsYHNQREQO80KenK8xaEcKIAEAQBBSWVuJGfjlu5JXjZmklurrbIcDHCS4O4oeLnJsV+Dn6Go6cyUBxmQoAIJEA/f3c8Mhgb4QGuOvV5TMYhojIaEgkElH/l2ltaa4NZnlFChyPvY5fYjJwI79COwHcxd4KDw7wQkSIF7zcbUWrlQxDhbIaN/LLkZVfjuv55cjKr9B+XVmlbnQdV0drBHR1QoCPEwK8neDd0a5dgodarcGZyzn48dQ1xCXnaeflOdpa4qGBXTBqkDfc9fTUMcMQEZEOuDnK8dRDvvj7yJ5IzijCsZhM/BZ3AwUllfjmlxR880sKeno5ICLEC8P6ecKuA29PYqqqazTIuflXyLmeV46sgtqv646qNEYqlcDDSY5OrjZwtLVE2o0SpGeVIL9IifyiGzjxZ+1NlK0tzeDXxQn+3rUBqYtr214SIq9IgZ9PX8ORM9dQWPpXvX19XfHIYG+E9fJoMP9O3zAMERHpkEQigV9XJ/h1dcKLf+uNM5dz8cvZTMQm5iIlsxgpmcXYfvAiQgM9MGKAF0IC3GFhrt9/OOj+aTQCbpZUIiu/HDcKyrWnt7LyK5BbWIGm5vw72Vmi063LT9Q9Orl2gLtThwY/K4rKaqRkFONyeiESrt5E4rUiKFU1+PPWGw6A2tNVbvYWCE4Fgnq4IcDHGW6O1vf1Lki1RkBsQi4On0pHbGKu9iiQvY0MD4XWHgXq6NLhvr9PYmEYIiJqJxbmZhjSpxOG9OmE4jIVTsRdx7GYTFy5UYJT8dk4FZ8NC3MpPJw7oJNLB3R0+etjRxcbuDhYc76RgahQViMpowiJ6YVIuFqIpIzaUHI31pZmt0JOw9BzP5Pv5VYWCPZ1RbBv7bsv1RoBGTmlSLhVx+X0QuQVKpBbXI2fz1zHz2dqr93lZGeFAB8nBHrXHkHq1tm+0aM5BcVKHIm+hp+jr6Hg1psVAKBPDxc8Msgbg4I6GmSYZxgiIhKBg60lnhjWHU8M64707FL8EpOJ47GZKCpTITO3DJm5ZQ3WMTeTwsNZfisk2dwKSbWBydXBWq8mpJoSQRCQc1OBhPSbSEivDUDXckobXMvKTCqBh3MHbcjxdPsr/DjaWurk+lRmUgl8OtnDp5M9Rj/gAwC4nlOIX05dQoXaBinXS3HlRgkKSyvxx/ks/HE+CwBgKTODr5ejdt6RIAj46fQ1nL2coz2KZSuXYWSoFx4Z7I3OrjZtXnt7YhgiIhKZd0c7THu8FyY/Goj8IgWyCiqQfeuRVVCO7IIK5NxUoEatwfW82jklQG69bZibSeDuJEdHF5vbjibVhiY3RwaltlRVrUbq9eLaoz7phUhML0JxecO5PR2dO8Df2xEBt462eLnb6sXcGSc7K/TqIkdAgB/kcjkqq2qQklFce/To1qNCWa19N+SdenVzxiODvfFAUEejufI6wxARkZ6oO3Lg4dwB8Kv/nFojoKBYiexb4ShLG5YqkHOzAtU1Gu2VuRvbrptT7RElZzsrdLC2qH1Y1X60qftau8wc1pb881CnqLRSGxIS0wuRer0ENer6t2sxN5Oip5dD7SRlb0f4d3WCo51h3LvOSmaOoB4uCOrhAqB2flNmXhkSrv4VjipVNRjarzMeGeRtlO+C5E87EZEBMJPWHvlxd5Kj7x0X69VoBBSUKG87mlShDU3ZBRWoqtFoP28uqVQCuaU5LMw0cDheArsOlncPULeWy63ModEIqFFrUF2jQY1agxq1gOoaNWpqBFSr1aiuEVBTo0Z13XJ1/fHVNRrU1Nzx9a2PGkGAtWVtULOSmcHaqvZza5m59nMrmTnkluawsjS7NdYC1rc+b87RMY1GwNWskr+OklwtRG6hosE4BxtLBPg4wb9r7WmkHl72sDA3jqMkUqkEXT3s0NXDDo8M9ha7nHbBMEREZOCkUsmtK23LtbctqaPR1F6cry4klVaoUKGsRrmyGhV1j8pqlCtqP1Yoq1GjFqDRCChXVgMAisrLADScw2RoLMyl2jB1+8PK0gwWZhJkZt9E9rfZUKrqX79HIgG6ethpT3cF+jjB3UnOe9AZEdHDkEajwccff4z//Oc/KC0txYABA7BkyRJ07dq10fFFRUV4//33ceLECQDAI488gkWLFkEu/+tCTocPH8b69euRmZkJb29vzJs3D8OGDWuXfoiI9IlUKoGLQ+291upOgzRFEASoqtWoUFbjZlEZLiWmws2jM6o1Zn+Fp9sDlLIa5bdClLKyBlIpYG5eGy4szM1grv0ohYW5tOFH87ssv+OjhZkUkACqqhooVDVQqmpQqVJDeevz2x+V9b5Wa09pVddoUF1Tpb0v1t1YW5rDr2vtXJ8Abyf4dXXk7VSMnOhhaOPGjdi7dy+WL18Od3d3rFq1Ci+++CK+//57yGQNL0I2e/ZsqFQqfPrppygtLcXixYvx7rvv4oMPPgAAnD59GvPmzcPChQsxePBgfPPNN5g1axYOHDiA7t27t3d7REQGRSKRwEpWe7rJ2kJA2U1LBPi61vsPp6GprtE0EpJuBaeqGigra1BSrkRpcQGGD/SHr7cbL2FgYkQNQ1VVVdixYwfmzZuH4cOHAwDWrl2LoUOH4siRI3j00UfrjY+Li8OZM2dw6NAhbbB57733MH36dLzxxhtwd3fH1q1bERkZiQkTJgAAFixYgLi4OOzatQvvvfde+zZIRESiszCXwsJc1uRVvhUKBRISKtHVw5ZByASJ+h6/xMREVFRUYNCgQdpldnZ2CAwMxNmzZxuMj4mJgaura70jPAMHDoREIkFsbCw0Gg3OnTtXb3sAEBYWhpiYGN01QkRERAZL1CNDOTk5AICOHTvWW+7m5obs7OwG43NzcxuMlclkcHBwQHZ2NkpLS6FQKODh4dGs7d0PQRCgUDR8R0FrKJXKeh+NmSn1CphWv+zVeJlSv+zVOAmC0KyJ7qKGobodcefcIEtLS5SUlDQ6vrF5RJaWllCpVKisrLzr9lSqu9/srjmqq6uRkJDQqm3cTXp6uk62q49MqVfAtPplr8bLlPplr8ansdxwJ1HDkJVV7QWpqqqqtJ8DgEqlgrW1daPjq6oavgtApVJBLpfD0tJSu707n29se/fDwsICPXr0aNU27qRUKpGeng5vb+9W16fvTKlXwLT6Za/Gy5T6Za/GKTU1tVnjRA1Ddae88vLy0KVLF+3yvLw8+Pv7Nxjv4eGBo0eP1ltWVVWF4uJiuLu7w8HBAXK5HHl5efXG5OXlNTh1dr8kEonO3k1hbW1t0O/UuB+m1CtgWv2yV+NlSv2yV+PS3GtBiTqB2t/fHzY2NoiOjtYuKy0txeXLlxESEtJgfGhoKHJycnDt2jXtsrp1+/fvD4lEgv79++PMmTP11ouOjsaAAQN01AUREREZMlGPDMlkMkyYMAGrV6+Gk5MTOnfujFWrVsHDwwORkZFQq9UoLCyEra0trKysEBwcjP79+2POnDl45513oFAosGTJEowZMwbu7u4AgKlTp+Kll15CYGAghg0bhm+//RYJCQlYunSpmK0SERGRnhL99rmzZ8/G+PHj8dZbb+HZZ5+FmZkZtm/fDplMhuzsbISHh+PQoUMAag93ffzxx/D09MTkyZPx+uuvY9iwYXjnnXe02wsPD8eyZcvw5ZdfYuzYsTh9+jQ2b97MCy4SERFRo0S/ArWZmRnmzZuHefPmNXjO09MTSUlJ9ZY5Oztj3bp1TW5zzJgxGDNmTFuWSUREREZK9CNDRERERGJiGCIiIiKTxjBEREREJo1hiIiIiEyaRBAEQewi9N25c+cgCEKzLul9PwRBQHV1NSwsLJp9YShDZUq9AqbVL3s1XqbUL3s1TlVVVdprEDZF9HeTGQJd/bBIJJI2D1j6ypR6BUyrX/ZqvEypX/ZqnCQSSbP+hvPIEBEREZk0zhkiIiIik8YwRERERCaNYYiIiIhMGsMQERERmTSGISIiIjJpDENERERk0hiGiIiIyKQxDBEREZFJYxgiIiIik8YwRERERCaNYYiIiIhMGsMQERERmTSGIR3SaDRYt24dhg4diuDgYEybNg3Xrl276/iioiLMnTsXoaGhCA0Nxdtvvw2FQtGOFbdccXEx/vnPf2LYsGHo378/nn32WcTExNx1/P79++Hn59fg0dT3R5/cuHGj0fr/85//NDreUPdtdHR0o336+flh5MiRja5jqPt248aNmDhxYr1lCQkJmDBhAvr27YsHH3wQ27dvv+d2Dh8+jNGjRyMoKAiPP/44Tpw4oauSW6Wxfn/55Rc8+eST6NevHyIiIvDBBx+gsrKyye1EREQ02NdvvvmmLku/b431umjRogZ1Dxs2rMntGMK+vbPXiRMn3vV3+MCBA3fdjiHs1zYlkM6sX79eGDx4sHD8+HEhISFBmDZtmhAZGSmoVKpGx0+YMEH4+9//Lly8eFE4efKkMGLECGH+/PntXHXLTJ06VXjiiSeEs2fPCmlpacK//vUvoU+fPkJqamqj45cvXy5MmDBByMvLq/eoqalp58pb5tixY0JQUJCQm5tbr36lUtnoeEPdtyqVqsE++v3334XAwEDh66+/bnQdQ9y3O3fuFPz8/IQJEyZolxUWFgphYWHC4sWLhdTUVOGbb74RgoKChG+++eau2zl16pTQq1cvYffu3UJqaqqwYsUKoXfv3nf9PRBLY/2ePXtWCAgIELZs2SKkp6cLv/76qzB8+HBh4cKFd91OWVmZ4OfnJ/zvf/+rt69LS0vbo41maaxXQRCEsWPHCv/+97/r1X3z5s27bscQ9m1jvRYVFTX4XXzppZeERx55RCgrK2t0O4awX9saw5COqFQqoV+/fsKePXu0y0pKSoQ+ffoI33//fYPx586dE3x9fev9Yv3222+Cn5+fkJOT0y41t1R6errg6+srxMbGapdpNBohMjJS+PDDDxtdZ+rUqcL777/fXiW2uU2bNglPPPFEs8Ya8r69U1VVlfDoo48Kr7/++l3HGNK+zcnJEV544QWhb9++wiOPPFLvj8jmzZuFoUOHCtXV1dpla9asEUaNGnXX7U2bNq3B9+bpp58W3n777bYvvgWa6nfu3LnC1KlT640/cOCAEBgYeNf/wMXGxgq+vr5CSUmJTutuiaZ6rampEYKCgoQjR440e3v6vG+b6vVO3333nRAYGCgkJibedYw+71dd4WkyHUlMTERFRQUGDRqkXWZnZ4fAwECcPXu2wfiYmBi4urqie/fu2mUDBw6ERCJBbGxsu9TcUo6Ojvjkk0/Qu3dv7TKJRAJBEFBSUtLoOklJSejRo0d7ldjm7qd+Q963d/riiy+QnZ2NRYsW3XWMIe3bS5cuwd7eHgcPHkRwcHC952JiYhAaGgpzc3PtskGDBuHq1au4efNmg21pNBqcO3eu3u88AISFhTV5yrg9NdXvtGnTMH/+/Abr1NTUoLy8vNHtJSUlwdXVFXZ2djqptzWa6jU9PR0qlare72RT9H3fNtXr7RQKBVauXInJkyfDz8/vruP0eb/qivm9h1BL5OTkAAA6duxYb7mbmxuys7MbjM/NzW0wViaTwcHBodHx+sTOzg7Dhw+vt+zw4cPIyMhAeHh4g/GFhYUoKCjA2bNnsXv3bhQXFyM4OBhvvvkmfHx82qvsVklOToarqyuee+45pKeno2vXrnjllVcwdOjQBmMNed/eTqVSYfPmzZg8eTLc3NwaHWNo+zYiIgIRERGNPpeTkwNfX996y+r6zsrKgrOzc73nSktLoVAo4OHh0WAdfdnPTfUbGBhY7+uqqirs3LkTvXr1gpOTU6PrJCcnQy6XIyoqCnFxcXBycsK4ceMwadIkSKXi/l+7qV6Tk5MhkUiwa9cunDhxAlKpFMOHD8frr78OW1vbBuP1fd821evt9u7di4qKCsycObPJcfq8X3XFOLvSA0qlEkDtH73bWVpaQqVSNTr+zrFNjddnsbGx+Mc//oGRI0c2+guanJwMADAzM8MHH3yAtWvXQqFQ4LnnnkNBQUF7l3vfqqqqkJ6ejvLycrz++uv45JNPEBQUhBdffBGnTp1qMN5Y9u1///tfqFSqBhNRb2fo+/Z2lZWVjf7+Amh0v9VNNG7u77w+q6mpwfz585GamoolS5bcdVxKSgrKysowevRobN++HU8//TQ++ugjrF+/vh2rvX8pKSmQSqXo3LkzNm/ejAULFuDXX3/FK6+8Ao1G02C8MexbtVqN3bt347nnnms08N3OUPdra/DIkI5YWVkBqP3DWfc5UPuPqLW1daPjq6qqGixXqVSQy+W6K7SNHT16FG+++SaCg4Px73//u9ExgwYNwpkzZ2Bvb69dtmHDBowYMQL79u3DSy+91F7ltohMJsPZs2dhbm6u/cexd+/eSEtLw/bt2zF48OB6441l3x44cAAPP/wwHB0d7zrG0Pft7Rrbb3V/+Brbb3VBqbF1Gvud11d1IT86Ohrr1q1r8rTLzp07oVKpYGNjAwDw8/NDRUUFNm3ahKioKL09ihAVFYUpU6ZoTwP5+vrC1dUVTz/9NOLj4xv0bAz79syZM8jKysJTTz11z7GGul9bw/g60hN1p0Xy8vLqLc/Ly2twqBUAPDw8GoytqqpCcXEx3N3ddVdoG/r8888RFRWFYcOGYevWrfVC4J1u/2MJ1P5x8fT0RG5urq7LbBNyubzB/xJ9fX0brd8Y9m1hYSHi4uIwevToe4419H1bp7H9Vvd1Y/vNwcEBcrm82b/z+igvLw/PP/884uLisHXr1nueerGwsND+wazj6+sLhUJx1/mC+kAikTSYD1N3SrRuisPtjGHfHj16FH369IGXl9c9xxrqfm0NhiEd8ff3h42NDaKjo7XLSktLcfnyZYSEhDQYHxoaipycnHrXYqlbt3///rovuJX27NmDf/3rX3j++efx4YcfNnpa6PaxYWFh9a5fUl5ejvT0dIOYeJuYmIh+/fo1mDh58eLFRus39H0LAOfOnYNEIsHAgQObHGfo+/Z2oaGhiI2NhVqt1i47deoUfHx8GswXAmr/wPbv3x9nzpyptzw6OhoDBgzQeb2tVVJSgsmTJ6OwsBB79uxpMFn4ThqNBhEREdi0aVO95fHx8XBxcWnyCKLY5s6dixdeeKHesvj4eABo9OfU0PctUDt94V77FDDs/doaDEM6IpPJMGHCBKxevRrHjh1DYmIi5syZAw8PD0RGRkKtViM/P1/7RyM4OBj9+/fHnDlzcOHCBZw+fRpLlizBmDFj9P7owdWrV7Fs2TJERkZixowZuHnzJvLz85Gfn4+ysrIGvY4YMQKCIGD+/PlISUlBfHw8oqKi4OTkhLFjx4rczb35+vqiZ8+eePfddxETE4O0tDQsX74cf/75J15++WWj2rd1EhMT4eXl1eCUgLHt29s9+eSTKC8vx+LFi5Gamop9+/Zh165dmDFjhnZMWVkZCgsLtV9PnToVP/zwA3bu3Im0tDSsXLkSCQkJmDx5shgt3Jfly5cjMzMTq1atgpOTk/Z3OD8/XxsIb+9XKpVi1KhR2LZtm/YNE1999RW2bduG1157TcxW7umxxx7DH3/8gU2bNiEjIwO//vor/vGPf+Cxxx7TvsPMmPatWq1GampqgzcE1DGW/doqIr+136jV1NQIK1euFAYNGiT07dtXePHFF4XMzExBEAQhMzNT8PX1Fb799lvt+IKCAiEqKkro27evEBYWJixZskSorKwUq/xm27Rpk+Dr69voY8GCBY32evnyZWHatGnCgAEDhP79+wtRUVFCVlaWiF3cn5s3bwqLFi0ShgwZIgQFBQlPP/20cPbsWUEQjGvf1lmyZInw1FNPNVhuTPt2wYIFDa7Pcv78eeGpp54SevfuLYwYMULYvXt3g3VGjBhRb9n+/fuFyMhIISgoSBg7dqxw8uRJndfeErf3q1arhaCgoLv+Htf9u3Vnv9XV1cLGjRuFkSNHCr169RJGjRolfPXVV6L005TG9u2PP/4ojBkzRujTp48wZMgQYcWKFfV+Jw113zbWa0FBgeDr6yucOHHirusY4n5tSxJBEASxAxkRERGRWHiajIiIiEwawxARERGZNIYhIiIiMmkMQ0RERGTSGIaIiIjIpDEMERERkUljGCIiIiKTxjBEREREJo13rScig7Bw4ULs37//rs87ODjUuxdge/Dz88Orr76KqKiodn1dImpbDENEZDBcXV3x8ccfN/qcuTn/OSOiluG/HkRkMGQyGfr27St2GURkZBiGiMioTJw4EZ07d4aPjw8+++wzKJVKhIWF4R//+Ae8vLy04+Lj4/Hhhx/i4sWLqK6uxsCBAzF37lz07NlTO+bmzZtYs2YNjh8/DqVSicDAQLzxxhsYMGCAdkzdne2PHDmC6upqDB06FEuWLIGzs3O79k1ELccJ1ERkUGpqahp93H7P6WPHjuHbb7/F4sWL8d577yExMRGTJk2CQqEAAJw+fRrPPvssNBoNli5divfffx/Z2dl45plnkJaWBgBQKBR45plncPLkScydOxcff/wxOnTogOnTp2vHAMBnn32G6upqfPTRR5gzZw5++eUXvPvuu+37TSGiVuGRISIyGDdu3ECvXr0afe61117DK6+8AqA2yHz77bfo0qULAKBbt24YO3Ys9u/fj+effx5r1qyBl5cXtm3bBjMzMwBAeHg4IiMjsX79enz44YfYv38/MjMzceDAAfj7+wMAQkJCMGbMGJw9exbdu3cHAAQFBWHlypUAgMGDB+PChQs4ceKETr8PRNS2GIaIyGC4urpi06ZNjT7n7u6u/bxfv37aIAQAgYGB8PLyQkxMDMaOHYv4+HjMmjVLG4QAwM7ODiNGjMCvv/4KAIiJiYGnp6c2CAGApaUlDh8+XO91bz9lBgBeXl4oLS1teZNE1O4YhojIYMhkMgQFBd1znJubW4Nlzs7OKC0tRVlZGQRBgIuLS4MxLi4uKCsrAwAUFxc3a96PXC6v97VUKq13yo6I9B/nDBGR0SkuLm6wrKCgAE5OTrC1tYVEIkFBQUGDMfn5+XBwcAAA2NraorCwsMGYuLg4pKSktHXJRCQihiEiMjpxcXH1gsylS5dw/fp1DB48GHK5HL1798ahQ4egVqu1Y8rKynD8+HHtaa+QkBBkZmYiKSlJO6aqqgpRUVH4+uuv268ZItI5niYjIoNRVVWFP//8867P+/r6AgCUSiVefPFFzJw5ExUVFVi7di18fX3x2GOPAQDmzp2LF154AdOnT8eECRNQXV2NTz75BFVVVXj11VcBAOPGjcPu3bsxc+ZMvPbaa3BycsIXX3yByspKTJw4Uee9ElH7YRgiIoORn5+Pp59++q7Pf/PNNwBqj+oMGjQIixcvBgBERERg/vz5kMlkAGrf9bVz506sW7cOb7zxBmQyGUJCQvDBBx9orzNkY2ODzz//HCtXrsTSpUtRU1OD4OBg7N69u97kbCIyfBKBM/2IyIjUHbXZvXu3yJUQkaHgnCEiIiIyaQxDREREZNJ4moyIiIhMGo8MERERkUljGCIiIiKTxjBEREREJo1hiIiIiEwawxARERGZNIYhIiIiMmkMQ0RERGTSGIaIiIjIpP0/NCmlAQDRMvYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 20;\n",
    "\n",
    "# Initialize lists to store loss and accuracy values\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train one epoch and get the training loss\n",
    "    train_loss = train_one_epoch(modified_model_CIFAR_10, optimizer, train_loader, device, epoch)\n",
    "    \n",
    "    # Append the training loss to the list\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Print training progress\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.5f}\")\n",
    "    \n",
    "# Plotting the loss curve\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.legend()\n",
    "plt.savefig('training_loss_curve.png')  # Save the loss curve plot\n",
    "\n",
    "# Closing the tensorboard writer\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./weights') is False:\n",
    "    os.makedirs('./weights')\n",
    "\n",
    "PATH = './weights2'\n",
    "\n",
    "torch.save(modified_model_CIFAR_10.state_dict(), f'{PATH}/model{3}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModifiedVGG16(\n",
      "  (vgg16): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): ReLU(inplace=True)\n",
      "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (15): ReLU(inplace=True)\n",
      "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (18): ReLU(inplace=True)\n",
      "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (20): ReLU(inplace=True)\n",
      "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (22): ReLU(inplace=True)\n",
      "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (25): ReLU(inplace=True)\n",
      "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (27): ReLU(inplace=True)\n",
      "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (29): ReLU(inplace=True)\n",
      "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "updated_model = './weights2/model3.pth'\n",
    "modified_model_CIFAR_10.load_state_dict(torch.load(updated_model))\n",
    "print(modified_model_CIFAR_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cross-Entropy Loss: 1.6874\n",
      "Accuracy: 0.7100\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_images = 0\n",
    "\n",
    "for images, labels in test_loader:\n",
    "\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    outputs = modified_model_0(images)\n",
    "    \n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    total_loss += loss.item()\n",
    "    \n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    total_images += labels.size(0)\n",
    "    \n",
    "    correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "average_loss = total_loss / len(test_loader)\n",
    "accuracy = correct_predictions / total_images\n",
    "\n",
    "print(f'Average Cross-Entropy Loss: {average_loss:.4f}')\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show accuracy and entropy per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: 2     is 72.0 %\n",
      "Average cross entropy for class: 2     is 1.67\n",
      "Accuracy for class: 8     is 66.0 %\n",
      "Average cross entropy for class: 8     is 1.67\n",
      "Accuracy for class: 5     is 60.0 %\n",
      "Average cross entropy for class: 5     is 1.67\n",
      "Accuracy for class: 4     is 60.0 %\n",
      "Average cross entropy for class: 4     is 1.67\n",
      "Accuracy for class: 3     is 48.0 %\n",
      "Average cross entropy for class: 3     is 1.67\n",
      "Accuracy for class: 9     is 84.0 %\n",
      "Average cross entropy for class: 9     is 1.67\n",
      "Accuracy for class: 1     is 92.0 %\n",
      "Average cross entropy for class: 1     is 1.67\n",
      "Accuracy for class: 0     is 80.0 %\n",
      "Average cross entropy for class: 0     is 1.67\n",
      "Accuracy for class: 6     is 66.0 %\n",
      "Average cross entropy for class: 6     is 1.67\n",
      "Accuracy for class: 7     is 84.0 %\n",
      "Average cross entropy for class: 7     is 1.67\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "total_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_images = 0\n",
    "correct_predictions_per_class = {}\n",
    "total_images_per_class = {}\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = modified_model_0(images)\n",
    "    loss = loss_fn(outputs, labels)\n",
    "    total_loss += loss.item()\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total_images += labels.size(0)\n",
    "    correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    # Update the per-class correct predictions and total images\n",
    "    for i, label in enumerate(labels):\n",
    "        label_str = str(label.item())\n",
    "        if label_str not in correct_predictions_per_class:\n",
    "            correct_predictions_per_class[label_str] = 0\n",
    "            total_images_per_class[label_str] = 0\n",
    "        if predicted[i] == labels[i]:\n",
    "            correct_predictions_per_class[label_str] += 1\n",
    "        total_images_per_class[label_str] += 1\n",
    "\n",
    "average_loss = total_loss / len(test_loader)\n",
    "accuracy = correct_predictions / total_images\n",
    "\n",
    "for classname, correct_count in correct_predictions_per_class.items():\n",
    "    total_images_for_class = total_images_per_class[classname]\n",
    "    accuracy = 100 * float(correct_count) / total_images_for_class\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
    "\n",
    "    pred_probs = torch.softmax(outputs, dim=1)\n",
    "    avg_cross_entropy = -torch.log(pred_probs[range(len(labels)), labels]).mean().item()\n",
    "    print(f'Average cross entropy for class: {classname:5s} is {avg_cross_entropy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 1.0000,  0.9922,  0.9922,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [ 1.0000,  0.9765,  0.9843,  ...,  0.9843,  0.9843,  0.9843],\n",
      "         [ 1.0000,  0.9765,  0.9843,  ...,  0.9843,  0.9843,  0.9843],\n",
      "         ...,\n",
      "         [ 1.0000,  0.9294,  0.3333,  ..., -0.6078, -0.5529,  0.6392],\n",
      "         [ 1.0000,  0.9686,  0.9765,  ..., -0.6863,  0.2706,  0.9686],\n",
      "         [ 1.0000,  0.9765,  0.9765,  ...,  0.1373,  0.9451,  0.9922]],\n",
      "\n",
      "        [[ 1.0000,  0.9922,  0.9922,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [ 1.0000,  0.9765,  0.9843,  ...,  0.9843,  0.9843,  0.9843],\n",
      "         [ 1.0000,  0.9765,  0.9843,  ...,  0.9843,  0.9843,  0.9843],\n",
      "         ...,\n",
      "         [ 1.0000,  0.9294,  0.3176,  ..., -0.6078, -0.5529,  0.6392],\n",
      "         [ 1.0000,  0.9686,  0.9686,  ..., -0.6863,  0.2706,  0.9686],\n",
      "         [ 1.0000,  0.9765,  0.9765,  ...,  0.1373,  0.9451,  0.9922]],\n",
      "\n",
      "        [[ 1.0000,  0.9922,  0.9922,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [ 1.0000,  0.9765,  0.9843,  ...,  0.9843,  0.9843,  0.9843],\n",
      "         [ 1.0000,  0.9765,  0.9843,  ...,  0.9843,  0.9843,  0.9843],\n",
      "         ...,\n",
      "         [ 1.0000,  0.9294,  0.3255,  ..., -0.6078, -0.5529,  0.6392],\n",
      "         [ 1.0000,  0.9686,  0.9686,  ..., -0.6863,  0.2706,  0.9686],\n",
      "         [ 1.0000,  0.9765,  0.9765,  ...,  0.1373,  0.9451,  0.9922]]]), 10)\n"
     ]
    }
   ],
   "source": [
    "class ModifiedImageFolder(ImageFolder):\n",
    "    def __init__(self, root, transform=None, target_transform=None):\n",
    "        super().__init__(root, transform=transform, target_transform=target_transform)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        original_image, original_label = super().__getitem__(index)\n",
    "        if original_label == 0:\n",
    "            # Change label 0 to 10\n",
    "            original_label = 10\n",
    "        return original_image, original_label\n",
    "\n",
    "# Define transformation of the datasets\n",
    "transform_2 = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # Resize images to the input size of VGG16\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize images\n",
    "])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# Create a modified dataset using ModifiedImageFolder\n",
    "train_dataset_100 = ModifiedImageFolder(root='CIFAR-100/train', transform=transform_2)\n",
    "\n",
    "train_loader_100 = torch.utils.data.DataLoader(train_dataset_100, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck','bycicle')\n",
    "\n",
    "print(train_dataset_100[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redefine the model from above in separate variable to avoid counter instantiation across models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ModifiedVGG16(nn.Module):\n",
    "#     def __init__(self, num_classes=10):\n",
    "#         super(ModifiedVGG16, self).__init__()\n",
    "#         # Load the pre-trained VGG16 model\n",
    "#         self.vgg16 = models.vgg16(weights='IMAGENET1K_V1')\n",
    "        \n",
    "#         # Modify the last fully connected layer to output 10 classes\n",
    "#         self.vgg16.classifier[6] = nn.Linear(4096, num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.vgg16(x)\n",
    "#         return x\n",
    "\n",
    "# CIFAR_100_model = ModifiedVGG16(num_classes=10)\n",
    "# print(CIFAR_100_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify the architecture s oit fits 11 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=11, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_for_11 = './weights/model2.pth'\n",
    "modified_model_CIFAR_10.load_state_dict(torch.load(model_for_11))\n",
    "\n",
    "num_classes = 11;\n",
    "\n",
    "# Change number of classes\n",
    "pretrained_weights_cifar_10 = modified_model_CIFAR_10.vgg16.classifier[6].weight.data.clone()\n",
    "pretrained_bias_cifar_10 = modified_model_CIFAR_10.vgg16.classifier[6].bias.data.clone()\n",
    "\n",
    "modified_model_CIFAR_10.vgg16.classifier[6] = torch.nn.Linear(in_features=4096, out_features=11, bias=True)\n",
    "modified_model_CIFAR_10.vgg16.classifier[6].weight.data = pretrained_weights_cifar_10\n",
    "modified_model_CIFAR_10.vgg16.classifier[6].bias.data = pretrained_bias_cifar_10\n",
    "\n",
    "model_100 = modified_model_CIFAR_10.vgg16\n",
    "print(model_100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3, 32, 32])\n",
      "[10]\n",
      "torch.Size([100, 3, 32, 32])\n",
      "[10]\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x316ea7910>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class CustomCIFAR100(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.dataset = datasets.ImageFolder(root, transform)  # \n",
    "        self.labels = []  # \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 获取父类中的数据和标签\n",
    "        image, label = self.dataset[index]\n",
    "\n",
    "        # 如果标签是0（假设0代表自行车类别），则将其改为10\n",
    "        # 否则，保持标签不变\n",
    "        if label == 0:\n",
    "            label = 10\n",
    "        self.labels.append(label)  # 将标签添加到列表中\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "train_set_100 = CustomCIFAR100('./CIFAR-100/train', transform_2)\n",
    "\n",
    "train_loader_100 = torch.utils.data.DataLoader(train_set_100, batch_size=100, shuffle=True)\n",
    "for iter, data in enumerate(train_loader_100):\n",
    "    images = data[0]\n",
    "    labels = data[1]\n",
    "    print(images.shape)\n",
    "    print(np.unique(labels))\n",
    "    break\n",
    "\n",
    "for iter, data in enumerate(train_loader_100):\n",
    "    images = data[0]\n",
    "    labels = data[1]\n",
    "    print(images.shape)\n",
    "    print(np.unique(labels))\n",
    "    break\n",
    "print(train_loader_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redefine optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(modified_model_CIFAR_10.parameters(),lr=0.01,momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the 11 classes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'ModifiedImageFolder' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'ModifiedImageFolder' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 64628) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_queue\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/multiprocessing/connection.py:440\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 440\u001b[0m     r \u001b[38;5;241m=\u001b[39m wait([\u001b[38;5;28mself\u001b[39m], timeout)\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/multiprocessing/connection.py:947\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 947\u001b[0m     ready \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mselect(timeout)\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     _error_if_any_worker_fails()\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 64628) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Loop over epochs\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Call train_one_epoch function for each epoch\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train_one_epoch(modified_model_CIFAR_10, optimizer, train_loader_100, device, epoch)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Append the training loss to the list\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[49], line 19\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, data_loader, device, epoch)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Wrap data_loader with tqdm for progress bar\u001b[39;00m\n\u001b[1;32m     17\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m tqdm(data_loader, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstdout)\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader):\n\u001b[1;32m     21\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     23\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data()\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_get_data()\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1145\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 64628) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "# Set Seaborn style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Initialize an empty list to store training losses\n",
    "train_losses = []\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "writer = SummaryWriter('./2_1/runs\"')\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(num_epochs):\n",
    "    # Call train_one_epoch function for each epoch\n",
    "    train_loss = train_one_epoch(modified_model_CIFAR_10, optimizer, train_loader_100, device, epoch)\n",
    "    \n",
    "    # Append the training loss to the list\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.5f}\")\n",
    "\n",
    "# Plot the loss curve using Seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=range(1, num_epochs + 1), y=train_losses, marker='o', color='b', label='Train Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('loss_curve_seaborn.png')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='./weights'\n",
    "torch.save(modified_model.state_dict(), f'{PATH}/2-1 11.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
